{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA3Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWeQWN4v/gm+sagjC/4VJ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ultan-Kearns/LYIT-Machine-Learning-Project/blob/main/CA3Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaYS6bFNmWuN"
      },
      "source": [
        "# Loading files and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8ySUe3n2zXfN",
        "outputId": "5f3f61c3-ad9b-4b94-8fb3-80c896086961"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded['wdbcwh.csv']), header = 0)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d4468ae8-e7b4-4519-a820-db42625e8847\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d4468ae8-e7b4-4519-a820-db42625e8847\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wdbcwh.csv to wdbcwh (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N963plximUXS"
      },
      "source": [
        "# Prepping and analyzing the data\n",
        "In this section we prep and analyze the data we do this by dividing the data into two groups training and testing.  We will train the models with the training data so that we can predict the values within the testing dataset.  We do this because we want to avoid overfitting the model which will yield great results on our trainingset but will be of no practical use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Qw95tszgIg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "d6ca6ea3-0feb-4ea9-e69c-a02ddc4c7db5"
      },
      "source": [
        "# Show dataset\n",
        "# split data into training and test datasets\n",
        "# will implement the sklearn method here instead of manually splitting just need to ensure is 50/50 before linear model\n",
        "trainingSet = df[0:284]\n",
        "testSet = df[285:570]\n",
        "xDiagnosis = trainingSet['Diagnosis']\n",
        "yDiagnnosis = testSet['Diagnosis']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)\n",
        "# Drop ID from the dataframe, it is not useful for our purposes except for identifying unique files\n",
        "trainingSet = trainingSet.drop(['ID'],axis=1)\n",
        "testSet = testSet.drop(['ID'],axis=1)\n",
        "X = trainingSet\n",
        "y = testSet\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-5c19e8d6ddb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0myDiagnnosis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Drop ID from the dataframe, it is not useful for our purposes except for identifying unique files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrainingSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2116\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [284, 142]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "IBokNCL3nyJ0",
        "outputId": "cf7124bd-1987-452e-f367-56a02447f25d"
      },
      "source": [
        "trainingSet.head()\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID Diagnosis  ...  Worst_Symmetry  Worst_Fractal_Dimension\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "_YNHFJMin8me",
        "outputId": "12ccaa07-6632-45ad-b344-5495766a4ea9"
      },
      "source": [
        "testSet.head()\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>8912521</td>\n",
              "      <td>B</td>\n",
              "      <td>12.58</td>\n",
              "      <td>18.40</td>\n",
              "      <td>79.83</td>\n",
              "      <td>489.0</td>\n",
              "      <td>0.08393</td>\n",
              "      <td>0.04216</td>\n",
              "      <td>0.00186</td>\n",
              "      <td>0.002924</td>\n",
              "      <td>0.1697</td>\n",
              "      <td>0.05855</td>\n",
              "      <td>0.2719</td>\n",
              "      <td>1.350</td>\n",
              "      <td>1.721</td>\n",
              "      <td>22.45</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.008008</td>\n",
              "      <td>0.00186</td>\n",
              "      <td>0.002924</td>\n",
              "      <td>0.02571</td>\n",
              "      <td>0.002015</td>\n",
              "      <td>13.50</td>\n",
              "      <td>23.08</td>\n",
              "      <td>85.56</td>\n",
              "      <td>564.1</td>\n",
              "      <td>0.10380</td>\n",
              "      <td>0.06624</td>\n",
              "      <td>0.005579</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>0.2505</td>\n",
              "      <td>0.06431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>8912909</td>\n",
              "      <td>B</td>\n",
              "      <td>11.94</td>\n",
              "      <td>20.76</td>\n",
              "      <td>77.87</td>\n",
              "      <td>441.0</td>\n",
              "      <td>0.08605</td>\n",
              "      <td>0.10110</td>\n",
              "      <td>0.06574</td>\n",
              "      <td>0.037910</td>\n",
              "      <td>0.1588</td>\n",
              "      <td>0.06766</td>\n",
              "      <td>0.2742</td>\n",
              "      <td>1.390</td>\n",
              "      <td>3.198</td>\n",
              "      <td>21.91</td>\n",
              "      <td>0.006719</td>\n",
              "      <td>0.051560</td>\n",
              "      <td>0.04387</td>\n",
              "      <td>0.016330</td>\n",
              "      <td>0.01872</td>\n",
              "      <td>0.008015</td>\n",
              "      <td>13.24</td>\n",
              "      <td>27.29</td>\n",
              "      <td>92.20</td>\n",
              "      <td>546.1</td>\n",
              "      <td>0.11160</td>\n",
              "      <td>0.28130</td>\n",
              "      <td>0.236500</td>\n",
              "      <td>0.115500</td>\n",
              "      <td>0.2465</td>\n",
              "      <td>0.09981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>8913</td>\n",
              "      <td>B</td>\n",
              "      <td>12.89</td>\n",
              "      <td>13.12</td>\n",
              "      <td>81.89</td>\n",
              "      <td>515.9</td>\n",
              "      <td>0.06955</td>\n",
              "      <td>0.03729</td>\n",
              "      <td>0.02260</td>\n",
              "      <td>0.011710</td>\n",
              "      <td>0.1337</td>\n",
              "      <td>0.05581</td>\n",
              "      <td>0.1532</td>\n",
              "      <td>0.469</td>\n",
              "      <td>1.115</td>\n",
              "      <td>12.68</td>\n",
              "      <td>0.004731</td>\n",
              "      <td>0.013450</td>\n",
              "      <td>0.01652</td>\n",
              "      <td>0.005905</td>\n",
              "      <td>0.01619</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>13.62</td>\n",
              "      <td>15.54</td>\n",
              "      <td>87.40</td>\n",
              "      <td>577.0</td>\n",
              "      <td>0.09616</td>\n",
              "      <td>0.11470</td>\n",
              "      <td>0.118600</td>\n",
              "      <td>0.053660</td>\n",
              "      <td>0.2309</td>\n",
              "      <td>0.06915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>8913049</td>\n",
              "      <td>B</td>\n",
              "      <td>11.26</td>\n",
              "      <td>19.96</td>\n",
              "      <td>73.72</td>\n",
              "      <td>394.1</td>\n",
              "      <td>0.08020</td>\n",
              "      <td>0.11810</td>\n",
              "      <td>0.09274</td>\n",
              "      <td>0.055880</td>\n",
              "      <td>0.2595</td>\n",
              "      <td>0.06233</td>\n",
              "      <td>0.4866</td>\n",
              "      <td>1.905</td>\n",
              "      <td>2.877</td>\n",
              "      <td>34.68</td>\n",
              "      <td>0.015740</td>\n",
              "      <td>0.082620</td>\n",
              "      <td>0.08099</td>\n",
              "      <td>0.034870</td>\n",
              "      <td>0.03418</td>\n",
              "      <td>0.006517</td>\n",
              "      <td>11.86</td>\n",
              "      <td>22.33</td>\n",
              "      <td>78.27</td>\n",
              "      <td>437.6</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>0.18430</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>0.093140</td>\n",
              "      <td>0.2955</td>\n",
              "      <td>0.07009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>89143601</td>\n",
              "      <td>B</td>\n",
              "      <td>11.37</td>\n",
              "      <td>18.89</td>\n",
              "      <td>72.17</td>\n",
              "      <td>396.0</td>\n",
              "      <td>0.08713</td>\n",
              "      <td>0.05008</td>\n",
              "      <td>0.02399</td>\n",
              "      <td>0.021730</td>\n",
              "      <td>0.2013</td>\n",
              "      <td>0.05955</td>\n",
              "      <td>0.2656</td>\n",
              "      <td>1.974</td>\n",
              "      <td>1.954</td>\n",
              "      <td>17.49</td>\n",
              "      <td>0.006538</td>\n",
              "      <td>0.013950</td>\n",
              "      <td>0.01376</td>\n",
              "      <td>0.009924</td>\n",
              "      <td>0.03416</td>\n",
              "      <td>0.002928</td>\n",
              "      <td>12.36</td>\n",
              "      <td>26.14</td>\n",
              "      <td>79.29</td>\n",
              "      <td>459.3</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.09708</td>\n",
              "      <td>0.075290</td>\n",
              "      <td>0.062030</td>\n",
              "      <td>0.3267</td>\n",
              "      <td>0.06994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID Diagnosis  ...  Worst_Symmetry  Worst_Fractal_Dimension\n",
              "285   8912521         B  ...          0.2505                  0.06431\n",
              "286   8912909         B  ...          0.2465                  0.09981\n",
              "287      8913         B  ...          0.2309                  0.06915\n",
              "288   8913049         B  ...          0.2955                  0.07009\n",
              "289  89143601         B  ...          0.3267                  0.06994\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yIKDylznco7",
        "outputId": "6e48ae87-4b91-4467-d62a-5cf5c1db5478"
      },
      "source": [
        "X_train.values"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.     , 16.74   , 21.59   , ...,  0.1813 ,  0.4863 ,  0.08633],\n",
              "       [ 1.     , 15.3    , 25.27   , ...,  0.2024 ,  0.4027 ,  0.09876],\n",
              "       [ 0.     , 11.43   , 17.31   , ...,  0.06402,  0.2584 ,  0.08096],\n",
              "       ...,\n",
              "       [ 0.     , 11.64   , 18.33   , ...,  0.1218 ,  0.2806 ,  0.09097],\n",
              "       [ 0.     , 14.29   , 16.82   , ...,  0.03333,  0.2458 ,  0.0612 ],\n",
              "       [ 0.     , 12.18   , 20.52   , ...,  0.07431,  0.2694 ,  0.06878]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0dDP2nXngqb",
        "outputId": "555f0d70-dfc0-4dcf-9d6f-af3218def213"
      },
      "source": [
        "X_test.values"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.     , 12.46   , 24.04   , ...,  0.221  ,  0.4366 ,  0.2075 ],\n",
              "       [ 1.     , 17.3    , 17.08   , ...,  0.1857 ,  0.3138 ,  0.08113],\n",
              "       [ 0.     , 16.84   , 19.46   , ...,  0.08436,  0.2527 ,  0.05972],\n",
              "       ...,\n",
              "       [ 1.     , 18.46   , 18.52   , ...,  0.1642 ,  0.3695 ,  0.08579],\n",
              "       [ 0.     , 12.47   , 18.6    , ...,  0.1015 ,  0.3014 ,  0.0875 ],\n",
              "       [ 1.     , 19.17   , 24.8    , ...,  0.1767 ,  0.3176 ,  0.1023 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "razAblX4qtPl",
        "outputId": "0003d6ec-3f11-4421-bd6d-92b495a8d040"
      },
      "source": [
        "# print test set shape will be same as training set\n",
        "print('test set shape: ',testSet.shape)\n",
        "print('trainingset shape: ', trainingSet.shape)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set shape:  (284, 32)\n",
            "trainingset shape:  (284, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hCqV87N0k7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "ca07a6f9-4cb5-4445-b894-c5fcd650a4ed"
      },
      "source": [
        "# Replace malignant with 1 and benign with 0\n",
        "trainingSet['Diagnosis'] = trainingSet['Diagnosis'].replace({'M':1,'B':0})\n",
        "testSet['Diagnosis'] = testSet['Diagnosis'].replace({'M':1,'B':0})\n",
        "X_train['Diagnosis'] = X_train['Diagnosis'].replace({'M':1,'B':0})\n",
        "y_train['Diagnosis'] = y_train['Diagnosis'].replace({'M':1,'B':0})\n",
        "X_test['Diagnosis'] = X_test['Diagnosis'].replace({'M':1,'B':0})\n",
        "y_test['Diagnosis'] = y_test['Diagnosis'].replace({'M':1,'B':0})"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-a2008bb6db8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainingSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6506\u001b[0m             return self.replace(\n\u001b[0;32m-> 6507\u001b[0;31m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6508\u001b[0m             )\n\u001b[1;32m   6509\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6551\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6552\u001b[0m                         \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6553\u001b[0;31m                         \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6554\u001b[0m                     )\n\u001b[1;32m   6555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, mask, regex)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Calculate the mask once, prior to the call of comp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex, mask)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_numeric_v_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;31m# GH#29553 avoid deprecation warnings from numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m         \u001b[0m_check_comparison_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_check_comparison_types\u001b[0;34m(result, a, b)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1981\u001b[0;31m                 \u001b[0;34mf\"Cannot compare types {repr(type_names[0])} and {repr(type_names[1])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m             )\n\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esjXl_W26F7C"
      },
      "source": [
        "## Show standard deviation of diagnose between sets\n",
        "\n",
        "Here we are showing both the standard deviation and variance of the sets, these are good methods for detecting outliers in our set, as we can see both sets have a somewhat high level of standard deviation.  We may try dropping columns from our dataframe to try and reduce this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BVX2LRv51ZB",
        "outputId": "675d9720-729a-491c-d688-7cf22feb0433"
      },
      "source": [
        "print('Standard deviation of diagnosis values in training set ',trainingSet['Diagnosis'].std())\n",
        "print('Variance of diagnosis values in training set: ', trainingSet['Diagnosis'].var())"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard deviation of diagnosis values in training set  0.5007708187683025\n",
            "Variance of diagnosis values in training set:  0.25077141292987615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POHC2Qe-51pY",
        "outputId": "fba71061-5307-46c2-8948-56fbdfbfe982"
      },
      "source": [
        "print('Standard deviation of diagnosis values in testing set ',testSet['Diagnosis'].std())\n",
        "print('Variance of diagnosis values in testing set: ', testSet['Diagnosis'].var())"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard deviation of diagnosis values in testing set  0.42531909439377436\n",
            "Variance of diagnosis values in testing set:  0.18089633205594033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTKjzh8miMId"
      },
      "source": [
        "## Show correlation\n",
        "Here we are showing the correlation between each feature within the dataset.  Correlation is determined by analyzing the values of different features and comparing them with each other.  A 1 means that the values of the feature match exactly a value of -1 means that the values have very little in common.  It is important that we use a wide variety of features which have low correlation as it will yield more accurate results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ftfJEYaBeJUe",
        "outputId": "db639920-e1a1-409b-d236-dd76a10bdd07"
      },
      "source": [
        "# Show correlation of our training set\n",
        "trainingSet.corr(method='pearson')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.013710</td>\n",
              "      <td>0.023517</td>\n",
              "      <td>0.159795</td>\n",
              "      <td>0.022735</td>\n",
              "      <td>0.027729</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.021982</td>\n",
              "      <td>0.041477</td>\n",
              "      <td>0.005841</td>\n",
              "      <td>0.055459</td>\n",
              "      <td>-0.003330</td>\n",
              "      <td>0.022353</td>\n",
              "      <td>0.064557</td>\n",
              "      <td>0.032873</td>\n",
              "      <td>0.026500</td>\n",
              "      <td>0.255367</td>\n",
              "      <td>0.118989</td>\n",
              "      <td>0.119863</td>\n",
              "      <td>0.171629</td>\n",
              "      <td>0.053914</td>\n",
              "      <td>0.115996</td>\n",
              "      <td>0.001848</td>\n",
              "      <td>0.091921</td>\n",
              "      <td>0.003659</td>\n",
              "      <td>0.006726</td>\n",
              "      <td>-0.003382</td>\n",
              "      <td>0.018689</td>\n",
              "      <td>0.027298</td>\n",
              "      <td>-0.002951</td>\n",
              "      <td>-0.016891</td>\n",
              "      <td>0.020004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diagnosis</th>\n",
              "      <td>0.013710</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.703347</td>\n",
              "      <td>0.485373</td>\n",
              "      <td>0.715981</td>\n",
              "      <td>0.667035</td>\n",
              "      <td>0.314811</td>\n",
              "      <td>0.574862</td>\n",
              "      <td>0.622877</td>\n",
              "      <td>0.732545</td>\n",
              "      <td>0.299413</td>\n",
              "      <td>-0.010482</td>\n",
              "      <td>0.503082</td>\n",
              "      <td>-0.044788</td>\n",
              "      <td>0.495760</td>\n",
              "      <td>0.503786</td>\n",
              "      <td>-0.097301</td>\n",
              "      <td>0.279346</td>\n",
              "      <td>0.163661</td>\n",
              "      <td>0.343616</td>\n",
              "      <td>-0.034470</td>\n",
              "      <td>0.047932</td>\n",
              "      <td>0.757582</td>\n",
              "      <td>0.510923</td>\n",
              "      <td>0.765564</td>\n",
              "      <td>0.705765</td>\n",
              "      <td>0.411572</td>\n",
              "      <td>0.586005</td>\n",
              "      <td>0.614477</td>\n",
              "      <td>0.782921</td>\n",
              "      <td>0.418117</td>\n",
              "      <td>0.337542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Radius</th>\n",
              "      <td>0.023517</td>\n",
              "      <td>0.703347</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416415</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.987866</td>\n",
              "      <td>0.093480</td>\n",
              "      <td>0.480938</td>\n",
              "      <td>0.626426</td>\n",
              "      <td>0.796443</td>\n",
              "      <td>0.137387</td>\n",
              "      <td>-0.321167</td>\n",
              "      <td>0.677440</td>\n",
              "      <td>-0.046538</td>\n",
              "      <td>0.673772</td>\n",
              "      <td>0.747920</td>\n",
              "      <td>-0.167242</td>\n",
              "      <td>0.210850</td>\n",
              "      <td>0.134393</td>\n",
              "      <td>0.328699</td>\n",
              "      <td>-0.063816</td>\n",
              "      <td>-0.045723</td>\n",
              "      <td>0.960578</td>\n",
              "      <td>0.358192</td>\n",
              "      <td>0.956904</td>\n",
              "      <td>0.936635</td>\n",
              "      <td>0.060297</td>\n",
              "      <td>0.374555</td>\n",
              "      <td>0.465421</td>\n",
              "      <td>0.705700</td>\n",
              "      <td>0.125492</td>\n",
              "      <td>-0.014133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Texture</th>\n",
              "      <td>0.159795</td>\n",
              "      <td>0.485373</td>\n",
              "      <td>0.416415</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.421372</td>\n",
              "      <td>0.400284</td>\n",
              "      <td>-0.009081</td>\n",
              "      <td>0.290253</td>\n",
              "      <td>0.319960</td>\n",
              "      <td>0.341718</td>\n",
              "      <td>0.057195</td>\n",
              "      <td>-0.074200</td>\n",
              "      <td>0.253619</td>\n",
              "      <td>0.270159</td>\n",
              "      <td>0.259921</td>\n",
              "      <td>0.259671</td>\n",
              "      <td>-0.090914</td>\n",
              "      <td>0.193028</td>\n",
              "      <td>0.101520</td>\n",
              "      <td>0.145774</td>\n",
              "      <td>-0.074104</td>\n",
              "      <td>0.029167</td>\n",
              "      <td>0.452690</td>\n",
              "      <td>0.909996</td>\n",
              "      <td>0.453423</td>\n",
              "      <td>0.437695</td>\n",
              "      <td>0.122798</td>\n",
              "      <td>0.343081</td>\n",
              "      <td>0.334205</td>\n",
              "      <td>0.365272</td>\n",
              "      <td>0.134964</td>\n",
              "      <td>0.169448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <td>0.022735</td>\n",
              "      <td>0.715981</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.421372</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.986137</td>\n",
              "      <td>0.136422</td>\n",
              "      <td>0.537753</td>\n",
              "      <td>0.670760</td>\n",
              "      <td>0.829846</td>\n",
              "      <td>0.177127</td>\n",
              "      <td>-0.265202</td>\n",
              "      <td>0.691965</td>\n",
              "      <td>-0.031106</td>\n",
              "      <td>0.695369</td>\n",
              "      <td>0.758219</td>\n",
              "      <td>-0.145823</td>\n",
              "      <td>0.259057</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.361056</td>\n",
              "      <td>-0.035995</td>\n",
              "      <td>-0.007175</td>\n",
              "      <td>0.960076</td>\n",
              "      <td>0.363902</td>\n",
              "      <td>0.962581</td>\n",
              "      <td>0.935908</td>\n",
              "      <td>0.094588</td>\n",
              "      <td>0.419872</td>\n",
              "      <td>0.504426</td>\n",
              "      <td>0.735387</td>\n",
              "      <td>0.154109</td>\n",
              "      <td>0.031018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Area</th>\n",
              "      <td>0.027729</td>\n",
              "      <td>0.667035</td>\n",
              "      <td>0.987866</td>\n",
              "      <td>0.400284</td>\n",
              "      <td>0.986137</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100207</td>\n",
              "      <td>0.466542</td>\n",
              "      <td>0.632035</td>\n",
              "      <td>0.790454</td>\n",
              "      <td>0.127187</td>\n",
              "      <td>-0.296071</td>\n",
              "      <td>0.718999</td>\n",
              "      <td>-0.016383</td>\n",
              "      <td>0.714238</td>\n",
              "      <td>0.800204</td>\n",
              "      <td>-0.113326</td>\n",
              "      <td>0.214851</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.320326</td>\n",
              "      <td>-0.030732</td>\n",
              "      <td>-0.021158</td>\n",
              "      <td>0.946216</td>\n",
              "      <td>0.335767</td>\n",
              "      <td>0.942642</td>\n",
              "      <td>0.943687</td>\n",
              "      <td>0.060027</td>\n",
              "      <td>0.343284</td>\n",
              "      <td>0.447492</td>\n",
              "      <td>0.674052</td>\n",
              "      <td>0.094772</td>\n",
              "      <td>-0.023343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.314811</td>\n",
              "      <td>0.093480</td>\n",
              "      <td>-0.009081</td>\n",
              "      <td>0.136422</td>\n",
              "      <td>0.100207</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.641173</td>\n",
              "      <td>0.530556</td>\n",
              "      <td>0.548984</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.602346</td>\n",
              "      <td>0.284035</td>\n",
              "      <td>0.093769</td>\n",
              "      <td>0.276355</td>\n",
              "      <td>0.231075</td>\n",
              "      <td>0.344493</td>\n",
              "      <td>0.366973</td>\n",
              "      <td>0.234304</td>\n",
              "      <td>0.329912</td>\n",
              "      <td>0.247269</td>\n",
              "      <td>0.308592</td>\n",
              "      <td>0.141084</td>\n",
              "      <td>0.039981</td>\n",
              "      <td>0.172760</td>\n",
              "      <td>0.133187</td>\n",
              "      <td>0.767162</td>\n",
              "      <td>0.476596</td>\n",
              "      <td>0.427929</td>\n",
              "      <td>0.473086</td>\n",
              "      <td>0.403487</td>\n",
              "      <td>0.503533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <td>0.021982</td>\n",
              "      <td>0.574862</td>\n",
              "      <td>0.480938</td>\n",
              "      <td>0.290253</td>\n",
              "      <td>0.537753</td>\n",
              "      <td>0.466542</td>\n",
              "      <td>0.641173</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.882018</td>\n",
              "      <td>0.837872</td>\n",
              "      <td>0.622507</td>\n",
              "      <td>0.579548</td>\n",
              "      <td>0.499131</td>\n",
              "      <td>0.108756</td>\n",
              "      <td>0.547029</td>\n",
              "      <td>0.461093</td>\n",
              "      <td>0.134379</td>\n",
              "      <td>0.751579</td>\n",
              "      <td>0.502106</td>\n",
              "      <td>0.595981</td>\n",
              "      <td>0.295615</td>\n",
              "      <td>0.496100</td>\n",
              "      <td>0.515626</td>\n",
              "      <td>0.293007</td>\n",
              "      <td>0.574312</td>\n",
              "      <td>0.485344</td>\n",
              "      <td>0.531429</td>\n",
              "      <td>0.859178</td>\n",
              "      <td>0.796732</td>\n",
              "      <td>0.806720</td>\n",
              "      <td>0.536742</td>\n",
              "      <td>0.671440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <td>0.041477</td>\n",
              "      <td>0.622877</td>\n",
              "      <td>0.626426</td>\n",
              "      <td>0.319960</td>\n",
              "      <td>0.670760</td>\n",
              "      <td>0.632035</td>\n",
              "      <td>0.530556</td>\n",
              "      <td>0.882018</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.906113</td>\n",
              "      <td>0.525676</td>\n",
              "      <td>0.400586</td>\n",
              "      <td>0.623912</td>\n",
              "      <td>0.141810</td>\n",
              "      <td>0.637533</td>\n",
              "      <td>0.607942</td>\n",
              "      <td>0.152112</td>\n",
              "      <td>0.697272</td>\n",
              "      <td>0.675275</td>\n",
              "      <td>0.662712</td>\n",
              "      <td>0.253480</td>\n",
              "      <td>0.493711</td>\n",
              "      <td>0.634134</td>\n",
              "      <td>0.301477</td>\n",
              "      <td>0.677017</td>\n",
              "      <td>0.618428</td>\n",
              "      <td>0.434185</td>\n",
              "      <td>0.723672</td>\n",
              "      <td>0.863081</td>\n",
              "      <td>0.828948</td>\n",
              "      <td>0.416502</td>\n",
              "      <td>0.513884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <td>0.005841</td>\n",
              "      <td>0.732545</td>\n",
              "      <td>0.796443</td>\n",
              "      <td>0.341718</td>\n",
              "      <td>0.829846</td>\n",
              "      <td>0.790454</td>\n",
              "      <td>0.548984</td>\n",
              "      <td>0.837872</td>\n",
              "      <td>0.906113</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.488583</td>\n",
              "      <td>0.197440</td>\n",
              "      <td>0.692004</td>\n",
              "      <td>0.060270</td>\n",
              "      <td>0.701631</td>\n",
              "      <td>0.694567</td>\n",
              "      <td>0.063849</td>\n",
              "      <td>0.508674</td>\n",
              "      <td>0.378952</td>\n",
              "      <td>0.571547</td>\n",
              "      <td>0.147161</td>\n",
              "      <td>0.264812</td>\n",
              "      <td>0.801603</td>\n",
              "      <td>0.315289</td>\n",
              "      <td>0.831994</td>\n",
              "      <td>0.777381</td>\n",
              "      <td>0.431098</td>\n",
              "      <td>0.653413</td>\n",
              "      <td>0.717161</td>\n",
              "      <td>0.894042</td>\n",
              "      <td>0.373838</td>\n",
              "      <td>0.363538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <td>0.055459</td>\n",
              "      <td>0.299413</td>\n",
              "      <td>0.137387</td>\n",
              "      <td>0.057195</td>\n",
              "      <td>0.177127</td>\n",
              "      <td>0.127187</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.622507</td>\n",
              "      <td>0.525676</td>\n",
              "      <td>0.488583</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.497342</td>\n",
              "      <td>0.302865</td>\n",
              "      <td>0.150201</td>\n",
              "      <td>0.307747</td>\n",
              "      <td>0.222083</td>\n",
              "      <td>0.090671</td>\n",
              "      <td>0.433621</td>\n",
              "      <td>0.324775</td>\n",
              "      <td>0.370057</td>\n",
              "      <td>0.491645</td>\n",
              "      <td>0.342675</td>\n",
              "      <td>0.176432</td>\n",
              "      <td>0.088787</td>\n",
              "      <td>0.215244</td>\n",
              "      <td>0.155144</td>\n",
              "      <td>0.396922</td>\n",
              "      <td>0.488051</td>\n",
              "      <td>0.450147</td>\n",
              "      <td>0.454006</td>\n",
              "      <td>0.705513</td>\n",
              "      <td>0.440456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <td>-0.003330</td>\n",
              "      <td>-0.010482</td>\n",
              "      <td>-0.321167</td>\n",
              "      <td>-0.074200</td>\n",
              "      <td>-0.265202</td>\n",
              "      <td>-0.296071</td>\n",
              "      <td>0.602346</td>\n",
              "      <td>0.579548</td>\n",
              "      <td>0.400586</td>\n",
              "      <td>0.197440</td>\n",
              "      <td>0.497342</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005697</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.041392</td>\n",
              "      <td>-0.085423</td>\n",
              "      <td>0.332319</td>\n",
              "      <td>0.585325</td>\n",
              "      <td>0.462722</td>\n",
              "      <td>0.343735</td>\n",
              "      <td>0.371762</td>\n",
              "      <td>0.700536</td>\n",
              "      <td>-0.255458</td>\n",
              "      <td>-0.029395</td>\n",
              "      <td>-0.204999</td>\n",
              "      <td>-0.240094</td>\n",
              "      <td>0.502224</td>\n",
              "      <td>0.496093</td>\n",
              "      <td>0.409352</td>\n",
              "      <td>0.203978</td>\n",
              "      <td>0.390225</td>\n",
              "      <td>0.763872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Radius_SE</th>\n",
              "      <td>0.022353</td>\n",
              "      <td>0.503082</td>\n",
              "      <td>0.677440</td>\n",
              "      <td>0.253619</td>\n",
              "      <td>0.691965</td>\n",
              "      <td>0.718999</td>\n",
              "      <td>0.284035</td>\n",
              "      <td>0.499131</td>\n",
              "      <td>0.623912</td>\n",
              "      <td>0.692004</td>\n",
              "      <td>0.302865</td>\n",
              "      <td>0.005697</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.243406</td>\n",
              "      <td>0.972352</td>\n",
              "      <td>0.957211</td>\n",
              "      <td>0.201987</td>\n",
              "      <td>0.367348</td>\n",
              "      <td>0.322876</td>\n",
              "      <td>0.509779</td>\n",
              "      <td>0.301331</td>\n",
              "      <td>0.229880</td>\n",
              "      <td>0.674935</td>\n",
              "      <td>0.142677</td>\n",
              "      <td>0.684464</td>\n",
              "      <td>0.694026</td>\n",
              "      <td>0.082291</td>\n",
              "      <td>0.252988</td>\n",
              "      <td>0.346585</td>\n",
              "      <td>0.488826</td>\n",
              "      <td>0.060922</td>\n",
              "      <td>0.016892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Texture_SE</th>\n",
              "      <td>0.064557</td>\n",
              "      <td>-0.044788</td>\n",
              "      <td>-0.046538</td>\n",
              "      <td>0.270159</td>\n",
              "      <td>-0.031106</td>\n",
              "      <td>-0.016383</td>\n",
              "      <td>0.093769</td>\n",
              "      <td>0.108756</td>\n",
              "      <td>0.141810</td>\n",
              "      <td>0.060270</td>\n",
              "      <td>0.150201</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.243406</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.271154</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.303251</td>\n",
              "      <td>0.294706</td>\n",
              "      <td>0.258153</td>\n",
              "      <td>0.286454</td>\n",
              "      <td>0.415421</td>\n",
              "      <td>0.336815</td>\n",
              "      <td>-0.087932</td>\n",
              "      <td>0.280642</td>\n",
              "      <td>-0.068049</td>\n",
              "      <td>-0.060673</td>\n",
              "      <td>-0.115005</td>\n",
              "      <td>-0.061490</td>\n",
              "      <td>-0.035530</td>\n",
              "      <td>-0.109725</td>\n",
              "      <td>-0.118351</td>\n",
              "      <td>-0.009581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <td>0.032873</td>\n",
              "      <td>0.495760</td>\n",
              "      <td>0.673772</td>\n",
              "      <td>0.259921</td>\n",
              "      <td>0.695369</td>\n",
              "      <td>0.714238</td>\n",
              "      <td>0.276355</td>\n",
              "      <td>0.547029</td>\n",
              "      <td>0.637533</td>\n",
              "      <td>0.701631</td>\n",
              "      <td>0.307747</td>\n",
              "      <td>0.041392</td>\n",
              "      <td>0.972352</td>\n",
              "      <td>0.271154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.943062</td>\n",
              "      <td>0.189566</td>\n",
              "      <td>0.421028</td>\n",
              "      <td>0.324444</td>\n",
              "      <td>0.540103</td>\n",
              "      <td>0.344142</td>\n",
              "      <td>0.239608</td>\n",
              "      <td>0.655208</td>\n",
              "      <td>0.150441</td>\n",
              "      <td>0.684400</td>\n",
              "      <td>0.670118</td>\n",
              "      <td>0.069558</td>\n",
              "      <td>0.294990</td>\n",
              "      <td>0.363431</td>\n",
              "      <td>0.502277</td>\n",
              "      <td>0.075075</td>\n",
              "      <td>0.037362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Area_SE</th>\n",
              "      <td>0.026500</td>\n",
              "      <td>0.503786</td>\n",
              "      <td>0.747920</td>\n",
              "      <td>0.259671</td>\n",
              "      <td>0.758219</td>\n",
              "      <td>0.800204</td>\n",
              "      <td>0.231075</td>\n",
              "      <td>0.461093</td>\n",
              "      <td>0.607942</td>\n",
              "      <td>0.694567</td>\n",
              "      <td>0.222083</td>\n",
              "      <td>-0.085423</td>\n",
              "      <td>0.957211</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.943062</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.132024</td>\n",
              "      <td>0.293268</td>\n",
              "      <td>0.247199</td>\n",
              "      <td>0.386144</td>\n",
              "      <td>0.215891</td>\n",
              "      <td>0.129655</td>\n",
              "      <td>0.727869</td>\n",
              "      <td>0.169519</td>\n",
              "      <td>0.734700</td>\n",
              "      <td>0.759050</td>\n",
              "      <td>0.071423</td>\n",
              "      <td>0.248083</td>\n",
              "      <td>0.344173</td>\n",
              "      <td>0.497246</td>\n",
              "      <td>0.039873</td>\n",
              "      <td>-0.013396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <td>0.255367</td>\n",
              "      <td>-0.097301</td>\n",
              "      <td>-0.167242</td>\n",
              "      <td>-0.090914</td>\n",
              "      <td>-0.145823</td>\n",
              "      <td>-0.113326</td>\n",
              "      <td>0.344493</td>\n",
              "      <td>0.134379</td>\n",
              "      <td>0.152112</td>\n",
              "      <td>0.063849</td>\n",
              "      <td>0.090671</td>\n",
              "      <td>0.332319</td>\n",
              "      <td>0.201987</td>\n",
              "      <td>0.303251</td>\n",
              "      <td>0.189566</td>\n",
              "      <td>0.132024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.374699</td>\n",
              "      <td>0.316298</td>\n",
              "      <td>0.393147</td>\n",
              "      <td>0.346827</td>\n",
              "      <td>0.431826</td>\n",
              "      <td>-0.210786</td>\n",
              "      <td>-0.179556</td>\n",
              "      <td>-0.191481</td>\n",
              "      <td>-0.172195</td>\n",
              "      <td>0.251313</td>\n",
              "      <td>-0.068557</td>\n",
              "      <td>-0.044344</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>-0.162861</td>\n",
              "      <td>0.036588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Compactness_SE</th>\n",
              "      <td>0.118989</td>\n",
              "      <td>0.279346</td>\n",
              "      <td>0.210850</td>\n",
              "      <td>0.193028</td>\n",
              "      <td>0.259057</td>\n",
              "      <td>0.214851</td>\n",
              "      <td>0.366973</td>\n",
              "      <td>0.751579</td>\n",
              "      <td>0.697272</td>\n",
              "      <td>0.508674</td>\n",
              "      <td>0.433621</td>\n",
              "      <td>0.585325</td>\n",
              "      <td>0.367348</td>\n",
              "      <td>0.294706</td>\n",
              "      <td>0.421028</td>\n",
              "      <td>0.293268</td>\n",
              "      <td>0.374699</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.759689</td>\n",
              "      <td>0.718673</td>\n",
              "      <td>0.458615</td>\n",
              "      <td>0.793503</td>\n",
              "      <td>0.199657</td>\n",
              "      <td>0.140524</td>\n",
              "      <td>0.257662</td>\n",
              "      <td>0.188619</td>\n",
              "      <td>0.226022</td>\n",
              "      <td>0.672486</td>\n",
              "      <td>0.645125</td>\n",
              "      <td>0.470539</td>\n",
              "      <td>0.312978</td>\n",
              "      <td>0.570630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Concavity_SE</th>\n",
              "      <td>0.119863</td>\n",
              "      <td>0.163661</td>\n",
              "      <td>0.134393</td>\n",
              "      <td>0.101520</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.234304</td>\n",
              "      <td>0.502106</td>\n",
              "      <td>0.675275</td>\n",
              "      <td>0.378952</td>\n",
              "      <td>0.324775</td>\n",
              "      <td>0.462722</td>\n",
              "      <td>0.322876</td>\n",
              "      <td>0.258153</td>\n",
              "      <td>0.324444</td>\n",
              "      <td>0.247199</td>\n",
              "      <td>0.316298</td>\n",
              "      <td>0.759689</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.760494</td>\n",
              "      <td>0.371987</td>\n",
              "      <td>0.752839</td>\n",
              "      <td>0.121498</td>\n",
              "      <td>0.055345</td>\n",
              "      <td>0.156335</td>\n",
              "      <td>0.125411</td>\n",
              "      <td>0.124195</td>\n",
              "      <td>0.398402</td>\n",
              "      <td>0.628329</td>\n",
              "      <td>0.363587</td>\n",
              "      <td>0.195292</td>\n",
              "      <td>0.384590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <td>0.171629</td>\n",
              "      <td>0.343616</td>\n",
              "      <td>0.328699</td>\n",
              "      <td>0.145774</td>\n",
              "      <td>0.361056</td>\n",
              "      <td>0.320326</td>\n",
              "      <td>0.329912</td>\n",
              "      <td>0.595981</td>\n",
              "      <td>0.662712</td>\n",
              "      <td>0.571547</td>\n",
              "      <td>0.370057</td>\n",
              "      <td>0.343735</td>\n",
              "      <td>0.509779</td>\n",
              "      <td>0.286454</td>\n",
              "      <td>0.540103</td>\n",
              "      <td>0.386144</td>\n",
              "      <td>0.393147</td>\n",
              "      <td>0.718673</td>\n",
              "      <td>0.760494</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388558</td>\n",
              "      <td>0.630059</td>\n",
              "      <td>0.298991</td>\n",
              "      <td>0.042076</td>\n",
              "      <td>0.337527</td>\n",
              "      <td>0.276401</td>\n",
              "      <td>0.136128</td>\n",
              "      <td>0.381483</td>\n",
              "      <td>0.501947</td>\n",
              "      <td>0.534901</td>\n",
              "      <td>0.133427</td>\n",
              "      <td>0.251643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <td>0.053914</td>\n",
              "      <td>-0.034470</td>\n",
              "      <td>-0.063816</td>\n",
              "      <td>-0.074104</td>\n",
              "      <td>-0.035995</td>\n",
              "      <td>-0.030732</td>\n",
              "      <td>0.247269</td>\n",
              "      <td>0.295615</td>\n",
              "      <td>0.253480</td>\n",
              "      <td>0.147161</td>\n",
              "      <td>0.491645</td>\n",
              "      <td>0.371762</td>\n",
              "      <td>0.301331</td>\n",
              "      <td>0.415421</td>\n",
              "      <td>0.344142</td>\n",
              "      <td>0.215891</td>\n",
              "      <td>0.346827</td>\n",
              "      <td>0.458615</td>\n",
              "      <td>0.371987</td>\n",
              "      <td>0.388558</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.379462</td>\n",
              "      <td>-0.111882</td>\n",
              "      <td>-0.146486</td>\n",
              "      <td>-0.076681</td>\n",
              "      <td>-0.101813</td>\n",
              "      <td>-0.024373</td>\n",
              "      <td>0.109147</td>\n",
              "      <td>0.097621</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.416234</td>\n",
              "      <td>0.093815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <td>0.115996</td>\n",
              "      <td>0.047932</td>\n",
              "      <td>-0.045723</td>\n",
              "      <td>0.029167</td>\n",
              "      <td>-0.007175</td>\n",
              "      <td>-0.021158</td>\n",
              "      <td>0.308592</td>\n",
              "      <td>0.496100</td>\n",
              "      <td>0.493711</td>\n",
              "      <td>0.264812</td>\n",
              "      <td>0.342675</td>\n",
              "      <td>0.700536</td>\n",
              "      <td>0.229880</td>\n",
              "      <td>0.336815</td>\n",
              "      <td>0.239608</td>\n",
              "      <td>0.129655</td>\n",
              "      <td>0.431826</td>\n",
              "      <td>0.793503</td>\n",
              "      <td>0.752839</td>\n",
              "      <td>0.630059</td>\n",
              "      <td>0.379462</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.049852</td>\n",
              "      <td>-0.018292</td>\n",
              "      <td>-0.014577</td>\n",
              "      <td>-0.037337</td>\n",
              "      <td>0.154118</td>\n",
              "      <td>0.374498</td>\n",
              "      <td>0.402998</td>\n",
              "      <td>0.203271</td>\n",
              "      <td>0.129552</td>\n",
              "      <td>0.554114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Radius</th>\n",
              "      <td>0.001848</td>\n",
              "      <td>0.757582</td>\n",
              "      <td>0.960578</td>\n",
              "      <td>0.452690</td>\n",
              "      <td>0.960076</td>\n",
              "      <td>0.946216</td>\n",
              "      <td>0.141084</td>\n",
              "      <td>0.515626</td>\n",
              "      <td>0.634134</td>\n",
              "      <td>0.801603</td>\n",
              "      <td>0.176432</td>\n",
              "      <td>-0.255458</td>\n",
              "      <td>0.674935</td>\n",
              "      <td>-0.087932</td>\n",
              "      <td>0.655208</td>\n",
              "      <td>0.727869</td>\n",
              "      <td>-0.210786</td>\n",
              "      <td>0.199657</td>\n",
              "      <td>0.121498</td>\n",
              "      <td>0.298991</td>\n",
              "      <td>-0.111882</td>\n",
              "      <td>-0.049852</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.440267</td>\n",
              "      <td>0.992816</td>\n",
              "      <td>0.985792</td>\n",
              "      <td>0.185176</td>\n",
              "      <td>0.455813</td>\n",
              "      <td>0.532632</td>\n",
              "      <td>0.766859</td>\n",
              "      <td>0.225640</td>\n",
              "      <td>0.092159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Texture</th>\n",
              "      <td>0.091921</td>\n",
              "      <td>0.510923</td>\n",
              "      <td>0.358192</td>\n",
              "      <td>0.909996</td>\n",
              "      <td>0.363902</td>\n",
              "      <td>0.335767</td>\n",
              "      <td>0.039981</td>\n",
              "      <td>0.293007</td>\n",
              "      <td>0.301477</td>\n",
              "      <td>0.315289</td>\n",
              "      <td>0.088787</td>\n",
              "      <td>-0.029395</td>\n",
              "      <td>0.142677</td>\n",
              "      <td>0.280642</td>\n",
              "      <td>0.150441</td>\n",
              "      <td>0.169519</td>\n",
              "      <td>-0.179556</td>\n",
              "      <td>0.140524</td>\n",
              "      <td>0.055345</td>\n",
              "      <td>0.042076</td>\n",
              "      <td>-0.146486</td>\n",
              "      <td>-0.018292</td>\n",
              "      <td>0.440267</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.441512</td>\n",
              "      <td>0.424130</td>\n",
              "      <td>0.276255</td>\n",
              "      <td>0.422060</td>\n",
              "      <td>0.399865</td>\n",
              "      <td>0.412982</td>\n",
              "      <td>0.276106</td>\n",
              "      <td>0.286848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <td>0.003659</td>\n",
              "      <td>0.765564</td>\n",
              "      <td>0.956904</td>\n",
              "      <td>0.453423</td>\n",
              "      <td>0.962581</td>\n",
              "      <td>0.942642</td>\n",
              "      <td>0.172760</td>\n",
              "      <td>0.574312</td>\n",
              "      <td>0.677017</td>\n",
              "      <td>0.831994</td>\n",
              "      <td>0.215244</td>\n",
              "      <td>-0.204999</td>\n",
              "      <td>0.684464</td>\n",
              "      <td>-0.068049</td>\n",
              "      <td>0.684400</td>\n",
              "      <td>0.734700</td>\n",
              "      <td>-0.191481</td>\n",
              "      <td>0.257662</td>\n",
              "      <td>0.156335</td>\n",
              "      <td>0.337527</td>\n",
              "      <td>-0.076681</td>\n",
              "      <td>-0.014577</td>\n",
              "      <td>0.992816</td>\n",
              "      <td>0.441512</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.977422</td>\n",
              "      <td>0.207156</td>\n",
              "      <td>0.506423</td>\n",
              "      <td>0.571999</td>\n",
              "      <td>0.795081</td>\n",
              "      <td>0.253364</td>\n",
              "      <td>0.129642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Area</th>\n",
              "      <td>0.006726</td>\n",
              "      <td>0.705765</td>\n",
              "      <td>0.936635</td>\n",
              "      <td>0.437695</td>\n",
              "      <td>0.935908</td>\n",
              "      <td>0.943687</td>\n",
              "      <td>0.133187</td>\n",
              "      <td>0.485344</td>\n",
              "      <td>0.618428</td>\n",
              "      <td>0.777381</td>\n",
              "      <td>0.155144</td>\n",
              "      <td>-0.240094</td>\n",
              "      <td>0.694026</td>\n",
              "      <td>-0.060673</td>\n",
              "      <td>0.670118</td>\n",
              "      <td>0.759050</td>\n",
              "      <td>-0.172195</td>\n",
              "      <td>0.188619</td>\n",
              "      <td>0.125411</td>\n",
              "      <td>0.276401</td>\n",
              "      <td>-0.101813</td>\n",
              "      <td>-0.037337</td>\n",
              "      <td>0.985792</td>\n",
              "      <td>0.424130</td>\n",
              "      <td>0.977422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.176310</td>\n",
              "      <td>0.414721</td>\n",
              "      <td>0.502514</td>\n",
              "      <td>0.722749</td>\n",
              "      <td>0.184752</td>\n",
              "      <td>0.074153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <td>-0.003382</td>\n",
              "      <td>0.411572</td>\n",
              "      <td>0.060297</td>\n",
              "      <td>0.122798</td>\n",
              "      <td>0.094588</td>\n",
              "      <td>0.060027</td>\n",
              "      <td>0.767162</td>\n",
              "      <td>0.531429</td>\n",
              "      <td>0.434185</td>\n",
              "      <td>0.431098</td>\n",
              "      <td>0.396922</td>\n",
              "      <td>0.502224</td>\n",
              "      <td>0.082291</td>\n",
              "      <td>-0.115005</td>\n",
              "      <td>0.069558</td>\n",
              "      <td>0.071423</td>\n",
              "      <td>0.251313</td>\n",
              "      <td>0.226022</td>\n",
              "      <td>0.124195</td>\n",
              "      <td>0.136128</td>\n",
              "      <td>-0.024373</td>\n",
              "      <td>0.154118</td>\n",
              "      <td>0.185176</td>\n",
              "      <td>0.276255</td>\n",
              "      <td>0.207156</td>\n",
              "      <td>0.176310</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.581686</td>\n",
              "      <td>0.533318</td>\n",
              "      <td>0.547021</td>\n",
              "      <td>0.514637</td>\n",
              "      <td>0.639132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <td>0.018689</td>\n",
              "      <td>0.586005</td>\n",
              "      <td>0.374555</td>\n",
              "      <td>0.343081</td>\n",
              "      <td>0.419872</td>\n",
              "      <td>0.343284</td>\n",
              "      <td>0.476596</td>\n",
              "      <td>0.859178</td>\n",
              "      <td>0.723672</td>\n",
              "      <td>0.653413</td>\n",
              "      <td>0.488051</td>\n",
              "      <td>0.496093</td>\n",
              "      <td>0.252988</td>\n",
              "      <td>-0.061490</td>\n",
              "      <td>0.294990</td>\n",
              "      <td>0.248083</td>\n",
              "      <td>-0.068557</td>\n",
              "      <td>0.672486</td>\n",
              "      <td>0.398402</td>\n",
              "      <td>0.381483</td>\n",
              "      <td>0.109147</td>\n",
              "      <td>0.374498</td>\n",
              "      <td>0.455813</td>\n",
              "      <td>0.422060</td>\n",
              "      <td>0.506423</td>\n",
              "      <td>0.414721</td>\n",
              "      <td>0.581686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.874010</td>\n",
              "      <td>0.791149</td>\n",
              "      <td>0.653209</td>\n",
              "      <td>0.828803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <td>0.027298</td>\n",
              "      <td>0.614477</td>\n",
              "      <td>0.465421</td>\n",
              "      <td>0.334205</td>\n",
              "      <td>0.504426</td>\n",
              "      <td>0.447492</td>\n",
              "      <td>0.427929</td>\n",
              "      <td>0.796732</td>\n",
              "      <td>0.863081</td>\n",
              "      <td>0.717161</td>\n",
              "      <td>0.450147</td>\n",
              "      <td>0.409352</td>\n",
              "      <td>0.346585</td>\n",
              "      <td>-0.035530</td>\n",
              "      <td>0.363431</td>\n",
              "      <td>0.344173</td>\n",
              "      <td>-0.044344</td>\n",
              "      <td>0.645125</td>\n",
              "      <td>0.628329</td>\n",
              "      <td>0.501947</td>\n",
              "      <td>0.097621</td>\n",
              "      <td>0.402998</td>\n",
              "      <td>0.532632</td>\n",
              "      <td>0.399865</td>\n",
              "      <td>0.571999</td>\n",
              "      <td>0.502514</td>\n",
              "      <td>0.533318</td>\n",
              "      <td>0.874010</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833510</td>\n",
              "      <td>0.572426</td>\n",
              "      <td>0.712982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <td>-0.002951</td>\n",
              "      <td>0.782921</td>\n",
              "      <td>0.705700</td>\n",
              "      <td>0.365272</td>\n",
              "      <td>0.735387</td>\n",
              "      <td>0.674052</td>\n",
              "      <td>0.473086</td>\n",
              "      <td>0.806720</td>\n",
              "      <td>0.828948</td>\n",
              "      <td>0.894042</td>\n",
              "      <td>0.454006</td>\n",
              "      <td>0.203978</td>\n",
              "      <td>0.488826</td>\n",
              "      <td>-0.109725</td>\n",
              "      <td>0.502277</td>\n",
              "      <td>0.497246</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.470539</td>\n",
              "      <td>0.363587</td>\n",
              "      <td>0.534901</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.203271</td>\n",
              "      <td>0.766859</td>\n",
              "      <td>0.412982</td>\n",
              "      <td>0.795081</td>\n",
              "      <td>0.722749</td>\n",
              "      <td>0.547021</td>\n",
              "      <td>0.791149</td>\n",
              "      <td>0.833510</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.531925</td>\n",
              "      <td>0.523025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <td>-0.016891</td>\n",
              "      <td>0.418117</td>\n",
              "      <td>0.125492</td>\n",
              "      <td>0.134964</td>\n",
              "      <td>0.154109</td>\n",
              "      <td>0.094772</td>\n",
              "      <td>0.403487</td>\n",
              "      <td>0.536742</td>\n",
              "      <td>0.416502</td>\n",
              "      <td>0.373838</td>\n",
              "      <td>0.705513</td>\n",
              "      <td>0.390225</td>\n",
              "      <td>0.060922</td>\n",
              "      <td>-0.118351</td>\n",
              "      <td>0.075075</td>\n",
              "      <td>0.039873</td>\n",
              "      <td>-0.162861</td>\n",
              "      <td>0.312978</td>\n",
              "      <td>0.195292</td>\n",
              "      <td>0.133427</td>\n",
              "      <td>0.416234</td>\n",
              "      <td>0.129552</td>\n",
              "      <td>0.225640</td>\n",
              "      <td>0.276106</td>\n",
              "      <td>0.253364</td>\n",
              "      <td>0.184752</td>\n",
              "      <td>0.514637</td>\n",
              "      <td>0.653209</td>\n",
              "      <td>0.572426</td>\n",
              "      <td>0.531925</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.582851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "      <td>0.020004</td>\n",
              "      <td>0.337542</td>\n",
              "      <td>-0.014133</td>\n",
              "      <td>0.169448</td>\n",
              "      <td>0.031018</td>\n",
              "      <td>-0.023343</td>\n",
              "      <td>0.503533</td>\n",
              "      <td>0.671440</td>\n",
              "      <td>0.513884</td>\n",
              "      <td>0.363538</td>\n",
              "      <td>0.440456</td>\n",
              "      <td>0.763872</td>\n",
              "      <td>0.016892</td>\n",
              "      <td>-0.009581</td>\n",
              "      <td>0.037362</td>\n",
              "      <td>-0.013396</td>\n",
              "      <td>0.036588</td>\n",
              "      <td>0.570630</td>\n",
              "      <td>0.384590</td>\n",
              "      <td>0.251643</td>\n",
              "      <td>0.093815</td>\n",
              "      <td>0.554114</td>\n",
              "      <td>0.092159</td>\n",
              "      <td>0.286848</td>\n",
              "      <td>0.129642</td>\n",
              "      <td>0.074153</td>\n",
              "      <td>0.639132</td>\n",
              "      <td>0.828803</td>\n",
              "      <td>0.712982</td>\n",
              "      <td>0.523025</td>\n",
              "      <td>0.582851</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               ID  ...  Worst_Fractal_Dimension\n",
              "ID                       1.000000  ...                 0.020004\n",
              "Diagnosis                0.013710  ...                 0.337542\n",
              "Mean_Radius              0.023517  ...                -0.014133\n",
              "Mean_Texture             0.159795  ...                 0.169448\n",
              "Mean_Perimeter           0.022735  ...                 0.031018\n",
              "Mean_Area                0.027729  ...                -0.023343\n",
              "Mean_Smoothness          0.006836  ...                 0.503533\n",
              "Mean_Compactness         0.021982  ...                 0.671440\n",
              "Mean_Concavity           0.041477  ...                 0.513884\n",
              "Mean_Concave_Points      0.005841  ...                 0.363538\n",
              "Mean_Symmetry            0.055459  ...                 0.440456\n",
              "Mean_Fractal_Dimension  -0.003330  ...                 0.763872\n",
              "Radius_SE                0.022353  ...                 0.016892\n",
              "Texture_SE               0.064557  ...                -0.009581\n",
              "Perimeter_SE             0.032873  ...                 0.037362\n",
              "Area_SE                  0.026500  ...                -0.013396\n",
              "Smoothness_SE            0.255367  ...                 0.036588\n",
              "Compactness_SE           0.118989  ...                 0.570630\n",
              "Concavity_SE             0.119863  ...                 0.384590\n",
              "Concave_Points_SE        0.171629  ...                 0.251643\n",
              "Symmetry_SE              0.053914  ...                 0.093815\n",
              "Fractal_Dimension_SE     0.115996  ...                 0.554114\n",
              "Worst_Radius             0.001848  ...                 0.092159\n",
              "Worst_Texture            0.091921  ...                 0.286848\n",
              "Worst_Perimeter          0.003659  ...                 0.129642\n",
              "Worst_Area               0.006726  ...                 0.074153\n",
              "Worst_Smoothness        -0.003382  ...                 0.639132\n",
              "Worst_Compactness        0.018689  ...                 0.828803\n",
              "Worst_Concavity          0.027298  ...                 0.712982\n",
              "Worst_Concave_Points    -0.002951  ...                 0.523025\n",
              "Worst_Symmetry          -0.016891  ...                 0.582851\n",
              "Worst_Fractal_Dimension  0.020004  ...                 1.000000\n",
              "\n",
              "[32 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJzjhwOkmmzq"
      },
      "source": [
        "# Training the linear regression model\n",
        "\n",
        "Here we are using linear regression to train the model to predict the diagnosis of breast cancer based on featurese in the trainingset as we can see here the model is accurately predicting the diagnosis of trainingset values, it has an r squared value of 1 which tells us that the fit is ideal for the training set.  This model also has a mean squared error of ~4.5 which tells us that the model is fairly accurate when predicting values in the trainingset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kz8R71_g0zy",
        "outputId": "564ddb11-662b-4020-ffe7-f0e2cacc0611"
      },
      "source": [
        "# Here we train a model to perform linear regression data set to predict the diagnosis\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "testArray = np.array(X_test.Diagnosis)\n",
        "testArray = testArray.reshape(2,71)\n",
        "trainArray = np.array(X_train.Diagnosis)\n",
        "trainArray = trainArray.reshape(2,71)\n",
        "# create the linear regression model by fitting training set to the test set\n",
        "regression_model = LinearRegression().fit(trainArray, testArray)\n",
        "# Score the model and retrive r^2 value\n",
        "rSquared = regression_model.score(trainArray, testArray)\n",
        "prediction = regression_model.predict(testArray)\n",
        "print('r^2 value: ', rSquared)\n",
        "print('mean_squared_error value: ', mean_squared_error(testArray, prediction))\n",
        "print('Prediction: ', regression_model.predict(testArray))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  1.0\n",
            "mean_squared_error value:  0.09463751608930375\n",
            "Prediction:  [[0.56410256 1.         0.         0.         0.56410256 0.43589744\n",
            "  0.56410256 0.         1.         0.43589744 0.         0.\n",
            "  0.         0.56410256 0.56410256 0.43589744 0.56410256 0.\n",
            "  0.         1.         0.         0.         0.43589744 0.56410256\n",
            "  0.56410256 0.43589744 1.         0.43589744 1.         1.\n",
            "  0.         0.         1.         1.         0.         0.\n",
            "  0.         1.         0.43589744 0.56410256 0.56410256 1.\n",
            "  0.56410256 0.56410256 0.56410256 0.56410256 0.         0.\n",
            "  0.         1.         1.         0.43589744 0.43589744 1.\n",
            "  0.56410256 0.56410256 1.         0.43589744 1.         1.\n",
            "  0.         0.         0.         0.         0.56410256 0.\n",
            "  1.         1.         0.43589744 0.         1.        ]\n",
            " [0.53846154 1.         0.         0.         0.53846154 0.46153846\n",
            "  0.53846154 0.         1.         0.46153846 0.         0.\n",
            "  0.         0.53846154 0.53846154 0.46153846 0.53846154 0.\n",
            "  0.         1.         0.         0.         0.46153846 0.53846154\n",
            "  0.53846154 0.46153846 1.         0.46153846 1.         1.\n",
            "  0.         0.         1.         1.         0.         0.\n",
            "  0.         1.         0.46153846 0.53846154 0.53846154 1.\n",
            "  0.53846154 0.53846154 0.53846154 0.53846154 0.         0.\n",
            "  0.         1.         1.         0.46153846 0.46153846 1.\n",
            "  0.53846154 0.53846154 1.         0.46153846 1.         1.\n",
            "  0.         0.         0.         0.         0.53846154 0.\n",
            "  1.         1.         0.46153846 0.         1.        ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P-fhUQKf-UX"
      },
      "source": [
        "Below we perform our predictions on the testset as you can see it also ideali fitted based on the r squared value and has a very low mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuEG397yfg2I",
        "outputId": "03224cc1-30fa-4a9e-de6f-f025a76ff459"
      },
      "source": [
        "# here we need to reshape the data using numpy so that the training data matches the testdata\n",
        "testArray = np.array(y_test.Diagnosis)\n",
        "testArray = testArray.reshape(2,71)\n",
        "trainArray = np.array(y_train.Diagnosis)\n",
        "trainArray = trainArray.reshape(2,71)\n",
        "regression_model = LinearRegression().fit(trainArray, testArray)\n",
        "\n",
        "prediction = regression_model.predict(testArray)\n",
        "print('r^2 value: ', regression_model.score(trainArray, testArray))\n",
        "print('mean_squared_error value: ', mean_squared_error(testArray, prediction))\n",
        "print('Prediction: ', regression_model.predict(np.abs(testArray)))\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  1.0\n",
            "mean_squared_error value:  0.11903075256271356\n",
            "Prediction:  [[0.         0.         0.5        0.         0.         1.\n",
            "  0.         0.         0.         0.         0.         0.5\n",
            "  0.5        0.         0.         0.         0.         0.\n",
            "  0.         0.5        0.5        0.         0.5        1.\n",
            "  0.5        0.         0.         0.         0.         0.5\n",
            "  0.5        0.         0.5        0.5        0.         0.\n",
            "  1.         0.         0.         0.         0.         0.\n",
            "  0.5        0.5        0.5        0.5        0.5        0.5\n",
            "  0.         0.         0.5        0.5        0.         0.\n",
            "  0.         0.         0.5        0.         0.5        0.5\n",
            "  0.5        0.         0.5        0.         0.         0.\n",
            "  0.5        0.5        0.5        0.5        0.5       ]\n",
            " [0.         0.         0.42307692 0.         0.         1.\n",
            "  0.         0.         0.         0.         0.         0.42307692\n",
            "  0.42307692 0.         0.         0.         0.         0.\n",
            "  0.         0.42307692 0.42307692 0.         0.57692308 1.\n",
            "  0.42307692 0.         0.         0.         0.         0.57692308\n",
            "  0.42307692 0.         0.42307692 0.57692308 0.         0.\n",
            "  1.         0.         0.         0.         0.         0.\n",
            "  0.42307692 0.57692308 0.42307692 0.57692308 0.57692308 0.42307692\n",
            "  0.         0.         0.42307692 0.57692308 0.         0.\n",
            "  0.         0.         0.57692308 0.         0.42307692 0.42307692\n",
            "  0.42307692 0.         0.42307692 0.         0.         0.\n",
            "  0.57692308 0.42307692 0.42307692 0.42307692 0.42307692]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp4yQz779N2-",
        "outputId": "30ca65ae-8a77-42a8-98cf-3df6780954c1"
      },
      "source": [
        "print(y_test.head())"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Diagnosis  Mean_Radius  ...  Worst_Symmetry  Worst_Fractal_Dimension\n",
            "294          0       12.720  ...          0.2369                  0.06922\n",
            "538          0        7.729  ...          0.3058                  0.09938\n",
            "442          0       13.780  ...          0.1859                  0.06810\n",
            "494          0       13.160  ...          0.2687                  0.07429\n",
            "360          0       12.540  ...          0.2233                  0.05521\n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FLPpNx2d1w6_",
        "outputId": "4a0c9222-b65e-4263-c343-9ddc25b3216b"
      },
      "source": [
        "# We can also train the model to predict values in the test set with a high degree of accuracy as shown below\n",
        "# In this example I have chosen to predict the mean radius of the test set based on the values in the trainingset\n",
        "testArray = np.array(y_test.Mean_Radius)\n",
        "testArray = testArray.reshape(2,71)\n",
        "trainArray = np.array(y_train.Mean_Radius)\n",
        "trainArray = trainArray.reshape(2,71)\n",
        "regression_model = LinearRegression().fit(trainArray, testArray)\n",
        "rSquared = regression_model.score(trainArray, testArray)\n",
        "prediction = regression_model.predict(testArray)\n",
        "print('r^2 value: ', rSquared)\n",
        "print('mean_squared_error value: ', mean_squared_error(testArray, prediction))\n",
        "print('Prediction training set: ', regression_model.predict(testArray))\n",
        "plt.scatter(testArray,prediction)\n",
        "plt.plot(testArray,prediction, color='Red')"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  1.0\n",
            "mean_squared_error value:  7.031219341500106\n",
            "Prediction training set:  [[11.84555714 11.41352779 19.64151587 12.48320842 12.18621314 20.50410235\n",
            "  11.21013847 12.48541711 11.65399067 11.10918052 12.62906636 12.83240936\n",
            "  16.25524145 14.68657921 14.49877823 11.12289174 12.5549461  10.97084274\n",
            "  13.48454763 14.34193544 14.69533422 11.55013756 12.96629173 18.93218973\n",
            "  15.18153787 13.97357703 12.58244354 13.08779222  9.86314693 19.04074997\n",
            "  13.12934326 11.7062605  15.28419502 14.19875365 12.65216062 12.20236164\n",
            "  19.47907347 12.57765077 13.59776872 11.60966    12.30683235 10.9871048\n",
            "  16.34471586 14.3637395  13.2309101  15.59851894 12.86077424 14.80822604\n",
            "  13.59239141 10.07541462 13.52104239 16.08288083 12.13985109 13.53760255\n",
            "  11.12493672  8.38414833 16.90407305  8.55563159 18.26017675 17.29189119\n",
            "  14.16675239 12.29932943 14.97193926 10.96737089 13.04223755 12.20247359\n",
            "  15.66272248 14.44949373 14.22931404 14.7497563  11.697677  ]\n",
            " [12.02277011 10.65556159 18.49019563 12.61702341 12.29264509 20.38161451\n",
            "  10.94188891 12.70085123 11.72769445 11.23468894 12.69823929 12.46332637\n",
            "  15.26769628 14.61986278 14.48129621 11.4019999  12.34310572 10.82389917\n",
            "  13.55824232 13.32282529 14.22639037 11.25938929 13.39432137 19.83715135\n",
            "  14.05115057 13.87513094 12.61740757 13.28086319  9.77401184 19.55109021\n",
            "  13.27494939 11.47789796 14.72152244 14.5603762  12.79881304 12.25275607\n",
            "  18.66694895 12.50545727 13.47676842 11.69318064 12.30918876 10.5896357\n",
            "  15.68792336 14.59210204 12.38291537 16.3233653  13.40727036 14.20953406\n",
            "  14.10424194 10.43450697 12.86580567 16.27841739 12.40143992 13.85609095\n",
            "  11.10766851  8.26274771 17.63335929  8.74604409 16.95187774 16.83525709\n",
            "  13.874603   12.16324901 14.45027187 11.0294855  13.31062267 11.68104822\n",
            "  16.42296959 14.31134804 13.83371006 14.37756175 11.88537099]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
            "  \"multioutput='uniform_average').\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f533f621f50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f542750>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f542910>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f542ad0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f542c90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f542e10>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54b090>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54b250>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54b410>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f542e50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54b750>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54b910>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54bad0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54bc90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54be50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f54bfd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551210>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f5513d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551590>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551750>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551910>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551ad0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551c90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551e50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f551fd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f555210>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f5553d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f555590>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f542150>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f555890>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f555a50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f555c10>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f555dd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f555f90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55b190>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55b350>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55b510>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55b6d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55b890>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55ba50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55bc10>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55bdd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55bf90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55c190>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55c350>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55c510>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55c6d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55c890>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55ca50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55cc10>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55cdd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f55cf90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2190>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2350>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2510>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e26d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2890>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2a50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2c10>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2dd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e2f90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6190>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6350>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6510>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e66d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6890>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6a50>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6c10>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6dd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4e6f90>,\n",
              " <matplotlib.lines.Line2D at 0x7f533f4ea190>]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "DKwJFrThHm5J",
        "outputId": "423416c2-2cae-4500-c6e4-73b2b5fa40a2"
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>0</td>\n",
              "      <td>12.720</td>\n",
              "      <td>13.78</td>\n",
              "      <td>81.78</td>\n",
              "      <td>492.1</td>\n",
              "      <td>0.09667</td>\n",
              "      <td>0.08393</td>\n",
              "      <td>0.012880</td>\n",
              "      <td>0.019240</td>\n",
              "      <td>0.1638</td>\n",
              "      <td>0.06100</td>\n",
              "      <td>0.1807</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>1.340</td>\n",
              "      <td>13.38</td>\n",
              "      <td>0.006064</td>\n",
              "      <td>0.011800</td>\n",
              "      <td>0.006564</td>\n",
              "      <td>0.007978</td>\n",
              "      <td>0.01374</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>13.500</td>\n",
              "      <td>17.48</td>\n",
              "      <td>88.54</td>\n",
              "      <td>553.7</td>\n",
              "      <td>0.12980</td>\n",
              "      <td>0.14720</td>\n",
              "      <td>0.052330</td>\n",
              "      <td>0.06343</td>\n",
              "      <td>0.2369</td>\n",
              "      <td>0.06922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>0</td>\n",
              "      <td>7.729</td>\n",
              "      <td>25.49</td>\n",
              "      <td>47.98</td>\n",
              "      <td>178.8</td>\n",
              "      <td>0.08098</td>\n",
              "      <td>0.04878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>0.07285</td>\n",
              "      <td>0.3777</td>\n",
              "      <td>1.4620</td>\n",
              "      <td>2.492</td>\n",
              "      <td>19.14</td>\n",
              "      <td>0.012660</td>\n",
              "      <td>0.009692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02882</td>\n",
              "      <td>0.006872</td>\n",
              "      <td>9.077</td>\n",
              "      <td>30.92</td>\n",
              "      <td>57.17</td>\n",
              "      <td>248.0</td>\n",
              "      <td>0.12560</td>\n",
              "      <td>0.08340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.3058</td>\n",
              "      <td>0.09938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>0</td>\n",
              "      <td>13.780</td>\n",
              "      <td>15.79</td>\n",
              "      <td>88.37</td>\n",
              "      <td>585.9</td>\n",
              "      <td>0.08817</td>\n",
              "      <td>0.06718</td>\n",
              "      <td>0.010550</td>\n",
              "      <td>0.009937</td>\n",
              "      <td>0.1405</td>\n",
              "      <td>0.05848</td>\n",
              "      <td>0.3563</td>\n",
              "      <td>0.4833</td>\n",
              "      <td>2.235</td>\n",
              "      <td>29.34</td>\n",
              "      <td>0.006432</td>\n",
              "      <td>0.011560</td>\n",
              "      <td>0.007741</td>\n",
              "      <td>0.005657</td>\n",
              "      <td>0.01227</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>15.270</td>\n",
              "      <td>17.50</td>\n",
              "      <td>97.90</td>\n",
              "      <td>706.6</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>0.10710</td>\n",
              "      <td>0.035170</td>\n",
              "      <td>0.03312</td>\n",
              "      <td>0.1859</td>\n",
              "      <td>0.06810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>0</td>\n",
              "      <td>13.160</td>\n",
              "      <td>20.54</td>\n",
              "      <td>84.06</td>\n",
              "      <td>538.7</td>\n",
              "      <td>0.07335</td>\n",
              "      <td>0.05275</td>\n",
              "      <td>0.018000</td>\n",
              "      <td>0.012560</td>\n",
              "      <td>0.1713</td>\n",
              "      <td>0.05888</td>\n",
              "      <td>0.3237</td>\n",
              "      <td>1.4730</td>\n",
              "      <td>2.326</td>\n",
              "      <td>26.07</td>\n",
              "      <td>0.007802</td>\n",
              "      <td>0.020520</td>\n",
              "      <td>0.013410</td>\n",
              "      <td>0.005564</td>\n",
              "      <td>0.02086</td>\n",
              "      <td>0.002701</td>\n",
              "      <td>14.500</td>\n",
              "      <td>28.46</td>\n",
              "      <td>95.29</td>\n",
              "      <td>648.3</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.16460</td>\n",
              "      <td>0.076980</td>\n",
              "      <td>0.04195</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.07429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>0</td>\n",
              "      <td>12.540</td>\n",
              "      <td>18.07</td>\n",
              "      <td>79.42</td>\n",
              "      <td>491.9</td>\n",
              "      <td>0.07436</td>\n",
              "      <td>0.02650</td>\n",
              "      <td>0.001194</td>\n",
              "      <td>0.005449</td>\n",
              "      <td>0.1528</td>\n",
              "      <td>0.05185</td>\n",
              "      <td>0.3511</td>\n",
              "      <td>0.9527</td>\n",
              "      <td>2.329</td>\n",
              "      <td>28.30</td>\n",
              "      <td>0.005783</td>\n",
              "      <td>0.004693</td>\n",
              "      <td>0.000793</td>\n",
              "      <td>0.003617</td>\n",
              "      <td>0.02043</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>13.720</td>\n",
              "      <td>20.98</td>\n",
              "      <td>86.82</td>\n",
              "      <td>585.7</td>\n",
              "      <td>0.09293</td>\n",
              "      <td>0.04327</td>\n",
              "      <td>0.003581</td>\n",
              "      <td>0.01635</td>\n",
              "      <td>0.2233</td>\n",
              "      <td>0.05521</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Diagnosis  Mean_Radius  ...  Worst_Symmetry  Worst_Fractal_Dimension\n",
              "294          0       12.720  ...          0.2369                  0.06922\n",
              "538          0        7.729  ...          0.3058                  0.09938\n",
              "442          0       13.780  ...          0.1859                  0.06810\n",
              "494          0       13.160  ...          0.2687                  0.07429\n",
              "360          0       12.540  ...          0.2233                  0.05521\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKLadrEnGqBU",
        "outputId": "3562bbb7-db2b-4d5d-ddfd-fc6bea10250b"
      },
      "source": [
        "testArray"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "        0, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGr0Ctt4eZ-b"
      },
      "source": [
        "# Examples of low and high correlation in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Zsy1970XoOZO",
        "outputId": "3f86cd90-b0d6-4e6b-e80d-2fcdfd344efc"
      },
      "source": [
        "# Example of positive Linear correlation between radius and perimeter\n",
        "# since these correlate highly we can remove one of them from set\n",
        "\n",
        "plt.scatter(trainingSet['Mean_Perimeter'],trainingSet['Mean_Radius'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe15ed74210>"
            ]
          },
          "metadata": {},
          "execution_count": 275
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hhwzfmxSoTtU",
        "outputId": "66eafc62-d80a-4930-8871-0761daf9881f"
      },
      "source": [
        "# example of low negative correlation\n",
        "plt.scatter(trainingSet['Mean_Fractal_Dimension'],trainingSet['Mean_Radius'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe15ec48810>"
            ]
          },
          "metadata": {},
          "execution_count": 276
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEhh-MN3TxmC"
      },
      "source": [
        "# KNN Predictions\n",
        "\n",
        "Here we are using KNN to make predictions based on a number of features fed into the model.  As we can see it's score is 0.84 which isn't perfect but it's better to avoid overfitting the model so that it can adapt to new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndm4DL8G1lG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5806a11-c0dc-4b5f-e975-bbd6e80860cc"
      },
      "source": [
        "# K Nearest Neighbour\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(trainingSet,testSet[['Diagnosis']])\n",
        "print(knn.score(trainingSet,testSet['Diagnosis']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.823943661971831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRpTbB2ysXs-",
        "outputId": "03a64e48-6a22-453c-de4f-d9441ddd1fea"
      },
      "source": [
        "testSet.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuntf9ZpWj4M",
        "outputId": "b801d127-cef4-42d4-ad05-793101554e2e"
      },
      "source": [
        "# Make prediction on testSet\n",
        "knn.predict(testSet)\n",
        "\n",
        "# maybe define list of features and use for loop to iterated\n",
        "\n",
        "# Taken from line 336 in dataset should be labelled as benign\n",
        "print(knn.predict([[-1,12.3,19.02,77.88,464.4,0.08313,0.04202,0.007756,0.008535,0.1539,0.05945,0.184,1.532,1.199,13.24,0.007881,0.008432,0.007004,0.006522,0.01939,0.002222,13.35,28.46,84.53,544.3,0.1222,0.09052,0.03619,0.03983,0.2554,0.07207]]))\n",
        "# Taken from line 402 of dataset should be malignant\n",
        "print(knn.predict([[-1,17.91,21.02,124.4,994,0.123,0.2576,0.3189,0.1198,0.2113,0.07115,0.403,0.7747,3.123,41.51,0.007159,0.03718,0.06165,0.01051,0.01591,0.005099,20.8,27.78,149.6,1304,0.1873,0.5917,0.9034,0.1964,0.3245,0.1198]]))\n",
        "# Taken from line 491 of dataset should be malignant\n",
        "print(knn.predict([[-1,16.69,20.2,107.1,857.6,0.07497,0.07112,0.03649,0.02307,0.1846,0.05325,0.2473,0.5679,1.775,22.95,0.002667,0.01446,0.01423,0.005297,0.01961,0.0017,19.18,26.56,127.3,1084,0.1009,0.292,0.2477,0.08737,0.4677,0.07623]]))\n",
        " # Taken from line 511 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1183,32.52,0.009538]]))\n",
        "# Taken from line 518 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1068,67.36,0.006176]]))\n",
        "# Line 470 should be malignant\n",
        "print(naive_bayes.predict([[0.09289,104.9,0.006766]]))\n",
        "# 324 Should be beningn\n",
        "print(naive_bayes.predict([[0.1134,16.57,0.00591]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZglfe8VT1ZP"
      },
      "source": [
        "# Naive Bayes prediction of diagnosis\n",
        "\n",
        "Here we use naive bayes on both sets to perform  the diagnosis based on a few features from the dataset, I choose the features used to train this model by randomly selecting features with low correlations, in Naive Bayes the weights of the features have no bearing on the output.  It was very interesting to see that the model is predicting accurately given the small number of trainingset features included in the model\n",
        "\n",
        "## References\n",
        "\n",
        "Sklearn documentation: https://scikit-learn.org/stable/modules/naive_bayes.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt8iXCKZNIvw",
        "outputId": "4e9affba-5717-4e99-851f-209639087f67"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(trainingSet[['Mean_Smoothness','Area_SE','Smoothness_SE']],trainingSet[['Diagnosis']])\n",
        "diagnosisPrediction = naive_bayes.predict(trainingSet[['Diagnosis']])\n",
        "print(diagnosisPrediction)\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        " % (trainingSet.shape[0], (trainingSet['Diagnosis'] != diagnosisPrediction).sum()))\n",
        "print('Score of the model: ',naive_bayes.score(trainingSet[['Mean_Smoothness','Area_SE','Smoothness_SE']],trainingSet[['Diagnosis']]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
            " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1]\n",
            "Number of mislabeled points out of a total 284 points : 0\n",
            "Score of the model:  0.8133802816901409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LlAxnEfQ8fC",
        "outputId": "a93f5171-f27d-42b2-8e4a-fd5081519b67"
      },
      "source": [
        "diagnosisPrediction = naive_bayes.predict(testSet[['Diagnosis']])\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        " % (testSet.shape[0], (testSet['Diagnosis'] != diagnosisPrediction).sum()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mislabeled points out of a total 284 points : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBeRLr5lZbKF"
      },
      "source": [
        "Let's make some predictions based on features from randomly selected rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCnd53LHXa9g",
        "outputId": "f59b4a16-f919-49b0-cc38-dff2102b9c11"
      },
      "source": [
        "# maybe define list of features and use for loop to iterated and randomize\n",
        "\n",
        "\n",
        "# Taken from line 336 in dataset should be labelled as benign\n",
        "print(naive_bayes.predict([[0.08313,13.24,0.007881]]))\n",
        " # Taken from line 511 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1183,32.52,0.009538]]))\n",
        "# Taken from line 518 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1068,67.36,0.006176]]))\n",
        "# Line 470 should be malignant\n",
        "print(naive_bayes.predict([[0.09289,104.9,0.006766]]))\n",
        "# 324 Should be beningn\n",
        "print(naive_bayes.predict([[0.1134,16.57,0.00591]]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTT46nyNZiLw"
      },
      "source": [
        "As we see above the model performs very well, not 100% perfect but good enough for classification as it predicted 4/5 or 80% of the diagnosis values for the given row\n",
        "Judiging by the Naive Bayes score we achieved which was around 81% this is to be expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIr--wdrUvT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc76803-2551-4be3-8f30-dd4971ef0ec6"
      },
      "source": [
        "\n",
        "# We drop these as seen above all of these correlate well with the mean_radius in both sets\n",
        "# removing these seems to reduce the mean squared error\n",
        "\n",
        "trainingSet = trainingSet.drop(['Mean_Perimeter'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Mean_Area'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Perimeter'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Area'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Mean_Concave_Points'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Texture'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Fractal_Dimension'],axis=1)\n",
        "\n",
        "testSet = testSet.drop(['Mean_Perimeter'],axis=1)\n",
        "testSet = testSet.drop(['Mean_Area'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Perimeter'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Area'],axis=1)\n",
        "testSet = testSet.drop(['Mean_Concave_Points'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Texture'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Fractal_Dimension'],axis=1)\n",
        "\n",
        "# Score the model and retrive r^2 value\n",
        "# Notice that both our rsquared and mean squared error values decrease after dropping these columns from dataframe\n",
        "print('r^2 value: ', rSquared)\n",
        "print('mean squared errors value: ', sqrt(mean_squared_error(trainingSet,testSet)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  1.0\n",
            "mean squared errors value:  13.339169290650567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "tPEJQxFw7W06",
        "outputId": "decfad55-6c25-42cb-8563-e81627495a85"
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>0</td>\n",
              "      <td>12.720</td>\n",
              "      <td>13.78</td>\n",
              "      <td>81.78</td>\n",
              "      <td>492.1</td>\n",
              "      <td>0.09667</td>\n",
              "      <td>0.08393</td>\n",
              "      <td>0.012880</td>\n",
              "      <td>0.019240</td>\n",
              "      <td>0.1638</td>\n",
              "      <td>0.06100</td>\n",
              "      <td>0.1807</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>1.340</td>\n",
              "      <td>13.38</td>\n",
              "      <td>0.006064</td>\n",
              "      <td>0.011800</td>\n",
              "      <td>0.006564</td>\n",
              "      <td>0.007978</td>\n",
              "      <td>0.01374</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>13.500</td>\n",
              "      <td>17.48</td>\n",
              "      <td>88.54</td>\n",
              "      <td>553.7</td>\n",
              "      <td>0.12980</td>\n",
              "      <td>0.14720</td>\n",
              "      <td>0.052330</td>\n",
              "      <td>0.06343</td>\n",
              "      <td>0.2369</td>\n",
              "      <td>0.06922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>0</td>\n",
              "      <td>7.729</td>\n",
              "      <td>25.49</td>\n",
              "      <td>47.98</td>\n",
              "      <td>178.8</td>\n",
              "      <td>0.08098</td>\n",
              "      <td>0.04878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>0.07285</td>\n",
              "      <td>0.3777</td>\n",
              "      <td>1.4620</td>\n",
              "      <td>2.492</td>\n",
              "      <td>19.14</td>\n",
              "      <td>0.012660</td>\n",
              "      <td>0.009692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02882</td>\n",
              "      <td>0.006872</td>\n",
              "      <td>9.077</td>\n",
              "      <td>30.92</td>\n",
              "      <td>57.17</td>\n",
              "      <td>248.0</td>\n",
              "      <td>0.12560</td>\n",
              "      <td>0.08340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.3058</td>\n",
              "      <td>0.09938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>0</td>\n",
              "      <td>13.780</td>\n",
              "      <td>15.79</td>\n",
              "      <td>88.37</td>\n",
              "      <td>585.9</td>\n",
              "      <td>0.08817</td>\n",
              "      <td>0.06718</td>\n",
              "      <td>0.010550</td>\n",
              "      <td>0.009937</td>\n",
              "      <td>0.1405</td>\n",
              "      <td>0.05848</td>\n",
              "      <td>0.3563</td>\n",
              "      <td>0.4833</td>\n",
              "      <td>2.235</td>\n",
              "      <td>29.34</td>\n",
              "      <td>0.006432</td>\n",
              "      <td>0.011560</td>\n",
              "      <td>0.007741</td>\n",
              "      <td>0.005657</td>\n",
              "      <td>0.01227</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>15.270</td>\n",
              "      <td>17.50</td>\n",
              "      <td>97.90</td>\n",
              "      <td>706.6</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>0.10710</td>\n",
              "      <td>0.035170</td>\n",
              "      <td>0.03312</td>\n",
              "      <td>0.1859</td>\n",
              "      <td>0.06810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>0</td>\n",
              "      <td>13.160</td>\n",
              "      <td>20.54</td>\n",
              "      <td>84.06</td>\n",
              "      <td>538.7</td>\n",
              "      <td>0.07335</td>\n",
              "      <td>0.05275</td>\n",
              "      <td>0.018000</td>\n",
              "      <td>0.012560</td>\n",
              "      <td>0.1713</td>\n",
              "      <td>0.05888</td>\n",
              "      <td>0.3237</td>\n",
              "      <td>1.4730</td>\n",
              "      <td>2.326</td>\n",
              "      <td>26.07</td>\n",
              "      <td>0.007802</td>\n",
              "      <td>0.020520</td>\n",
              "      <td>0.013410</td>\n",
              "      <td>0.005564</td>\n",
              "      <td>0.02086</td>\n",
              "      <td>0.002701</td>\n",
              "      <td>14.500</td>\n",
              "      <td>28.46</td>\n",
              "      <td>95.29</td>\n",
              "      <td>648.3</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.16460</td>\n",
              "      <td>0.076980</td>\n",
              "      <td>0.04195</td>\n",
              "      <td>0.2687</td>\n",
              "      <td>0.07429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>0</td>\n",
              "      <td>12.540</td>\n",
              "      <td>18.07</td>\n",
              "      <td>79.42</td>\n",
              "      <td>491.9</td>\n",
              "      <td>0.07436</td>\n",
              "      <td>0.02650</td>\n",
              "      <td>0.001194</td>\n",
              "      <td>0.005449</td>\n",
              "      <td>0.1528</td>\n",
              "      <td>0.05185</td>\n",
              "      <td>0.3511</td>\n",
              "      <td>0.9527</td>\n",
              "      <td>2.329</td>\n",
              "      <td>28.30</td>\n",
              "      <td>0.005783</td>\n",
              "      <td>0.004693</td>\n",
              "      <td>0.000793</td>\n",
              "      <td>0.003617</td>\n",
              "      <td>0.02043</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>13.720</td>\n",
              "      <td>20.98</td>\n",
              "      <td>86.82</td>\n",
              "      <td>585.7</td>\n",
              "      <td>0.09293</td>\n",
              "      <td>0.04327</td>\n",
              "      <td>0.003581</td>\n",
              "      <td>0.01635</td>\n",
              "      <td>0.2233</td>\n",
              "      <td>0.05521</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Diagnosis  Mean_Radius  ...  Worst_Symmetry  Worst_Fractal_Dimension\n",
              "294          0       12.720  ...          0.2369                  0.06922\n",
              "538          0        7.729  ...          0.3058                  0.09938\n",
              "442          0       13.780  ...          0.1859                  0.06810\n",
              "494          0       13.160  ...          0.2687                  0.07429\n",
              "360          0       12.540  ...          0.2233                  0.05521\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM5qdiPE7i1r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}