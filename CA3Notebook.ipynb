{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA3Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeTClkv8qx4wpcxgEF3Ufl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ultan-Kearns/LYIT-Machine-Learning-Project/blob/main/CA3Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaYS6bFNmWuN"
      },
      "source": [
        "# Loading files and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "8ySUe3n2zXfN",
        "outputId": "87437da8-eda7-4c2d-82c8-cf7b1ece55c1"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded['wdbcwh.csv']), header = 0)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c25587a5-ac8e-4780-8677-8a66e0bfdc45\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c25587a5-ac8e-4780-8677-8a66e0bfdc45\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wdbcwh.csv to wdbcwh (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N963plximUXS"
      },
      "source": [
        "# Prepping and analyzing the data\n",
        "In this section we prep and analyze the data we do this by dividing the data into two groups training and testing.  We will train the models with the training data so that we can predict the values within the testing dataset.  We do this because we want to avoid overfitting the model which will yield great results on our trainingset but will be of no practical use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Qw95tszgIg"
      },
      "source": [
        "# Show dataset\n",
        "# split data into training and test datasets\n",
        "# will implement the sklearn method here instead of manually splitting just need to ensure is 50/50 before linear model\n",
        "trainingSet = df[0:284]\n",
        "testSet = df[285:570]\n",
        "xDiagnosis = trainingSet['Diagnosis']\n",
        "yDiagnnosis = testSet['Diagnosis']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)\n",
        "# Drop ID from the dataframe, it is not useful for our purposes except for identifying unique files\n",
        "trainingSet = trainingSet.drop(['ID'],axis=1)\n",
        "testSet = testSet.drop(['ID'],axis=1)\n",
        "X = trainingSet\n",
        "y = testSet\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "IBokNCL3nyJ0",
        "outputId": "8f29dfd7-01ae-445c-e6d9-44c8a12654c4"
      },
      "source": [
        "trainingSet.head()\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Diagnosis  Mean_Radius  ...  Worst_Symmetry  Worst_Fractal_Dimension\n",
              "0         M        17.99  ...          0.4601                  0.11890\n",
              "1         M        20.57  ...          0.2750                  0.08902\n",
              "2         M        19.69  ...          0.3613                  0.08758\n",
              "3         M        11.42  ...          0.6638                  0.17300\n",
              "4         M        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "_YNHFJMin8me",
        "outputId": "1643e19e-5759-4691-b6af-0ad4c6944ad4"
      },
      "source": [
        "testSet.head()\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>B</td>\n",
              "      <td>12.58</td>\n",
              "      <td>18.40</td>\n",
              "      <td>79.83</td>\n",
              "      <td>489.0</td>\n",
              "      <td>0.08393</td>\n",
              "      <td>0.04216</td>\n",
              "      <td>0.00186</td>\n",
              "      <td>0.002924</td>\n",
              "      <td>0.1697</td>\n",
              "      <td>0.05855</td>\n",
              "      <td>0.2719</td>\n",
              "      <td>1.350</td>\n",
              "      <td>1.721</td>\n",
              "      <td>22.45</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.008008</td>\n",
              "      <td>0.00186</td>\n",
              "      <td>0.002924</td>\n",
              "      <td>0.02571</td>\n",
              "      <td>0.002015</td>\n",
              "      <td>13.50</td>\n",
              "      <td>23.08</td>\n",
              "      <td>85.56</td>\n",
              "      <td>564.1</td>\n",
              "      <td>0.10380</td>\n",
              "      <td>0.06624</td>\n",
              "      <td>0.005579</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>0.2505</td>\n",
              "      <td>0.06431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>B</td>\n",
              "      <td>11.94</td>\n",
              "      <td>20.76</td>\n",
              "      <td>77.87</td>\n",
              "      <td>441.0</td>\n",
              "      <td>0.08605</td>\n",
              "      <td>0.10110</td>\n",
              "      <td>0.06574</td>\n",
              "      <td>0.037910</td>\n",
              "      <td>0.1588</td>\n",
              "      <td>0.06766</td>\n",
              "      <td>0.2742</td>\n",
              "      <td>1.390</td>\n",
              "      <td>3.198</td>\n",
              "      <td>21.91</td>\n",
              "      <td>0.006719</td>\n",
              "      <td>0.051560</td>\n",
              "      <td>0.04387</td>\n",
              "      <td>0.016330</td>\n",
              "      <td>0.01872</td>\n",
              "      <td>0.008015</td>\n",
              "      <td>13.24</td>\n",
              "      <td>27.29</td>\n",
              "      <td>92.20</td>\n",
              "      <td>546.1</td>\n",
              "      <td>0.11160</td>\n",
              "      <td>0.28130</td>\n",
              "      <td>0.236500</td>\n",
              "      <td>0.115500</td>\n",
              "      <td>0.2465</td>\n",
              "      <td>0.09981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>B</td>\n",
              "      <td>12.89</td>\n",
              "      <td>13.12</td>\n",
              "      <td>81.89</td>\n",
              "      <td>515.9</td>\n",
              "      <td>0.06955</td>\n",
              "      <td>0.03729</td>\n",
              "      <td>0.02260</td>\n",
              "      <td>0.011710</td>\n",
              "      <td>0.1337</td>\n",
              "      <td>0.05581</td>\n",
              "      <td>0.1532</td>\n",
              "      <td>0.469</td>\n",
              "      <td>1.115</td>\n",
              "      <td>12.68</td>\n",
              "      <td>0.004731</td>\n",
              "      <td>0.013450</td>\n",
              "      <td>0.01652</td>\n",
              "      <td>0.005905</td>\n",
              "      <td>0.01619</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>13.62</td>\n",
              "      <td>15.54</td>\n",
              "      <td>87.40</td>\n",
              "      <td>577.0</td>\n",
              "      <td>0.09616</td>\n",
              "      <td>0.11470</td>\n",
              "      <td>0.118600</td>\n",
              "      <td>0.053660</td>\n",
              "      <td>0.2309</td>\n",
              "      <td>0.06915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>B</td>\n",
              "      <td>11.26</td>\n",
              "      <td>19.96</td>\n",
              "      <td>73.72</td>\n",
              "      <td>394.1</td>\n",
              "      <td>0.08020</td>\n",
              "      <td>0.11810</td>\n",
              "      <td>0.09274</td>\n",
              "      <td>0.055880</td>\n",
              "      <td>0.2595</td>\n",
              "      <td>0.06233</td>\n",
              "      <td>0.4866</td>\n",
              "      <td>1.905</td>\n",
              "      <td>2.877</td>\n",
              "      <td>34.68</td>\n",
              "      <td>0.015740</td>\n",
              "      <td>0.082620</td>\n",
              "      <td>0.08099</td>\n",
              "      <td>0.034870</td>\n",
              "      <td>0.03418</td>\n",
              "      <td>0.006517</td>\n",
              "      <td>11.86</td>\n",
              "      <td>22.33</td>\n",
              "      <td>78.27</td>\n",
              "      <td>437.6</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>0.18430</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>0.093140</td>\n",
              "      <td>0.2955</td>\n",
              "      <td>0.07009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>B</td>\n",
              "      <td>11.37</td>\n",
              "      <td>18.89</td>\n",
              "      <td>72.17</td>\n",
              "      <td>396.0</td>\n",
              "      <td>0.08713</td>\n",
              "      <td>0.05008</td>\n",
              "      <td>0.02399</td>\n",
              "      <td>0.021730</td>\n",
              "      <td>0.2013</td>\n",
              "      <td>0.05955</td>\n",
              "      <td>0.2656</td>\n",
              "      <td>1.974</td>\n",
              "      <td>1.954</td>\n",
              "      <td>17.49</td>\n",
              "      <td>0.006538</td>\n",
              "      <td>0.013950</td>\n",
              "      <td>0.01376</td>\n",
              "      <td>0.009924</td>\n",
              "      <td>0.03416</td>\n",
              "      <td>0.002928</td>\n",
              "      <td>12.36</td>\n",
              "      <td>26.14</td>\n",
              "      <td>79.29</td>\n",
              "      <td>459.3</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.09708</td>\n",
              "      <td>0.075290</td>\n",
              "      <td>0.062030</td>\n",
              "      <td>0.3267</td>\n",
              "      <td>0.06994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Diagnosis  Mean_Radius  ...  Worst_Symmetry  Worst_Fractal_Dimension\n",
              "285         B        12.58  ...          0.2505                  0.06431\n",
              "286         B        11.94  ...          0.2465                  0.09981\n",
              "287         B        12.89  ...          0.2309                  0.06915\n",
              "288         B        11.26  ...          0.2955                  0.07009\n",
              "289         B        11.37  ...          0.3267                  0.06994\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yIKDylznco7",
        "outputId": "154dac49-283f-4f3a-d02d-f3b6ae3f9b6e"
      },
      "source": [
        "testSet.values"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['B', 12.58, 18.4, ..., 0.008772, 0.2505, 0.06431],\n",
              "       ['B', 11.94, 20.76, ..., 0.1155, 0.2465, 0.09981],\n",
              "       ['B', 12.89, 13.12, ..., 0.05366, 0.2309, 0.06915],\n",
              "       ...,\n",
              "       ['M', 16.6, 28.08, ..., 0.1418, 0.2218, 0.0782],\n",
              "       ['M', 20.6, 29.33, ..., 0.265, 0.4087, 0.124],\n",
              "       ['B', 7.76, 24.54, ..., 0.0, 0.2871, 0.07039]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0dDP2nXngqb",
        "outputId": "08fc4fc6-6ac8-45e6-c2fe-23cbee1b3e7a"
      },
      "source": [
        "trainingSet.values"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['M', 17.99, 10.38, ..., 0.2654, 0.4601, 0.1189],\n",
              "       ['M', 20.57, 17.77, ..., 0.18600000000000003, 0.275, 0.08902],\n",
              "       ['M', 19.69, 21.25, ..., 0.243, 0.3613, 0.08757999999999999],\n",
              "       ...,\n",
              "       ['B', 11.74, 14.02, ..., 0.0829, 0.3101, 0.06688],\n",
              "       ['M', 19.4, 18.18, ..., 0.2252, 0.359, 0.07787000000000001],\n",
              "       ['M', 16.24, 18.77, ..., 0.1732, 0.27699999999999997, 0.1063]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "razAblX4qtPl",
        "outputId": "f6fc5ea3-c855-48bd-dc81-ab26ffc11610"
      },
      "source": [
        "# print test set shape will be same as training set\n",
        "print('test set shape: ',testSet.shape)\n",
        "print('trainingset shape: ', trainingSet.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set shape:  (284, 31)\n",
            "trainingset shape:  (284, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hCqV87N0k7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a9cc79a4-a023-44bf-dc43-da2b3e8de7c3"
      },
      "source": [
        "# Replace malignant with 1 and benign with 0\n",
        "trainingSet['Diagnosis'] = trainingSet['Diagnosis'].replace({'M':1,'B':0})\n",
        "testSet['Diagnosis'] = testSet['Diagnosis'].replace({'M':1,'B':0})\n",
        "X_train['Diagnosis'] = X_train['Diagnosis'].replace({'M':1,'B':0})\n",
        "y_train['Diagnosis'] = y_train['Diagnosis'].replace({'M':1,'B':0})\n",
        "X_test['Diagnosis'] = X_test['Diagnosis'].replace({'M':1,'B':0})\n",
        "y_test['Diagnosis'] = y_test['Diagnosis'].replace({'M':1,'B':0})"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-a2008bb6db8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replace malignant with 1 and benign with 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainingSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6506\u001b[0m             return self.replace(\n\u001b[0;32m-> 6507\u001b[0;31m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6508\u001b[0m             )\n\u001b[1;32m   6509\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6551\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6552\u001b[0m                         \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6553\u001b[0;31m                         \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6554\u001b[0m                     )\n\u001b[1;32m   6555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, mask, regex)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Calculate the mask once, prior to the call of comp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex, mask)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_numeric_v_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;31m# GH#29553 avoid deprecation warnings from numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m         \u001b[0m_check_comparison_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_check_comparison_types\u001b[0;34m(result, a, b)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1981\u001b[0;31m                 \u001b[0;34mf\"Cannot compare types {repr(type_names[0])} and {repr(type_names[1])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m             )\n\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esjXl_W26F7C"
      },
      "source": [
        "## Show standard deviation of diagnose between sets\n",
        "\n",
        "Here we are showing both the standard deviation and variance of the sets, these are good methods for detecting outliers in our set, as we can see both sets have a somewhat high level of standard deviation.  We may try dropping columns from our dataframe to try and reduce this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BVX2LRv51ZB",
        "outputId": "1d0636ce-712e-479a-d84e-11c7ea07227f"
      },
      "source": [
        "print('Standard deviation of diagnosis values in training set ',trainingSet['Diagnosis'].std())\n",
        "print('Variance of diagnosis values in training set: ', trainingSet['Diagnosis'].var())"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard deviation of diagnosis values in training set  0.5007708187683025\n",
            "Variance of diagnosis values in training set:  0.25077141292987615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POHC2Qe-51pY",
        "outputId": "b72bda8d-f08c-4e91-c916-97b85a1136cf"
      },
      "source": [
        "print('Standard deviation of diagnosis values in testing set ',testSet['Diagnosis'].std())\n",
        "print('Variance of diagnosis values in testing set: ', testSet['Diagnosis'].var())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard deviation of diagnosis values in testing set  0.42531909439377436\n",
            "Variance of diagnosis values in testing set:  0.18089633205594033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTKjzh8miMId"
      },
      "source": [
        "## Show correlation\n",
        "Here we are showing the correlation between each feature within the dataset.  Correlation is determined by analyzing the values of different features and comparing them with each other.  A 1 means that the values of the feature match exactly a value of -1 means that the values have very little in common.  It is important that we use a wide variety of features which have low correlation as it will yield more accurate results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ftfJEYaBeJUe",
        "outputId": "9e0211aa-2198-4292-d359-f5028c25999c"
      },
      "source": [
        "# Show correlation of our training set\n",
        "trainingSet.corr(method='pearson')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean_Radius</th>\n",
              "      <th>Mean_Texture</th>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <th>Mean_Area</th>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <th>Radius_SE</th>\n",
              "      <th>Texture_SE</th>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <th>Area_SE</th>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <th>Compactness_SE</th>\n",
              "      <th>Concavity_SE</th>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <th>Worst_Radius</th>\n",
              "      <th>Worst_Texture</th>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <th>Worst_Area</th>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Diagnosis</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.703347</td>\n",
              "      <td>0.485373</td>\n",
              "      <td>0.715981</td>\n",
              "      <td>0.667035</td>\n",
              "      <td>0.314811</td>\n",
              "      <td>0.574862</td>\n",
              "      <td>0.622877</td>\n",
              "      <td>0.732545</td>\n",
              "      <td>0.299413</td>\n",
              "      <td>-0.010482</td>\n",
              "      <td>0.503082</td>\n",
              "      <td>-0.044788</td>\n",
              "      <td>0.495760</td>\n",
              "      <td>0.503786</td>\n",
              "      <td>-0.097301</td>\n",
              "      <td>0.279346</td>\n",
              "      <td>0.163661</td>\n",
              "      <td>0.343616</td>\n",
              "      <td>-0.034470</td>\n",
              "      <td>0.047932</td>\n",
              "      <td>0.757582</td>\n",
              "      <td>0.510923</td>\n",
              "      <td>0.765564</td>\n",
              "      <td>0.705765</td>\n",
              "      <td>0.411572</td>\n",
              "      <td>0.586005</td>\n",
              "      <td>0.614477</td>\n",
              "      <td>0.782921</td>\n",
              "      <td>0.418117</td>\n",
              "      <td>0.337542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Radius</th>\n",
              "      <td>0.703347</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416415</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.987866</td>\n",
              "      <td>0.093480</td>\n",
              "      <td>0.480938</td>\n",
              "      <td>0.626426</td>\n",
              "      <td>0.796443</td>\n",
              "      <td>0.137387</td>\n",
              "      <td>-0.321167</td>\n",
              "      <td>0.677440</td>\n",
              "      <td>-0.046538</td>\n",
              "      <td>0.673772</td>\n",
              "      <td>0.747920</td>\n",
              "      <td>-0.167242</td>\n",
              "      <td>0.210850</td>\n",
              "      <td>0.134393</td>\n",
              "      <td>0.328699</td>\n",
              "      <td>-0.063816</td>\n",
              "      <td>-0.045723</td>\n",
              "      <td>0.960578</td>\n",
              "      <td>0.358192</td>\n",
              "      <td>0.956904</td>\n",
              "      <td>0.936635</td>\n",
              "      <td>0.060297</td>\n",
              "      <td>0.374555</td>\n",
              "      <td>0.465421</td>\n",
              "      <td>0.705700</td>\n",
              "      <td>0.125492</td>\n",
              "      <td>-0.014133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Texture</th>\n",
              "      <td>0.485373</td>\n",
              "      <td>0.416415</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.421372</td>\n",
              "      <td>0.400284</td>\n",
              "      <td>-0.009081</td>\n",
              "      <td>0.290253</td>\n",
              "      <td>0.319960</td>\n",
              "      <td>0.341718</td>\n",
              "      <td>0.057195</td>\n",
              "      <td>-0.074200</td>\n",
              "      <td>0.253619</td>\n",
              "      <td>0.270159</td>\n",
              "      <td>0.259921</td>\n",
              "      <td>0.259671</td>\n",
              "      <td>-0.090914</td>\n",
              "      <td>0.193028</td>\n",
              "      <td>0.101520</td>\n",
              "      <td>0.145774</td>\n",
              "      <td>-0.074104</td>\n",
              "      <td>0.029167</td>\n",
              "      <td>0.452690</td>\n",
              "      <td>0.909996</td>\n",
              "      <td>0.453423</td>\n",
              "      <td>0.437695</td>\n",
              "      <td>0.122798</td>\n",
              "      <td>0.343081</td>\n",
              "      <td>0.334205</td>\n",
              "      <td>0.365272</td>\n",
              "      <td>0.134964</td>\n",
              "      <td>0.169448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Perimeter</th>\n",
              "      <td>0.715981</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.421372</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.986137</td>\n",
              "      <td>0.136422</td>\n",
              "      <td>0.537753</td>\n",
              "      <td>0.670760</td>\n",
              "      <td>0.829846</td>\n",
              "      <td>0.177127</td>\n",
              "      <td>-0.265202</td>\n",
              "      <td>0.691965</td>\n",
              "      <td>-0.031106</td>\n",
              "      <td>0.695369</td>\n",
              "      <td>0.758219</td>\n",
              "      <td>-0.145823</td>\n",
              "      <td>0.259057</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.361056</td>\n",
              "      <td>-0.035995</td>\n",
              "      <td>-0.007175</td>\n",
              "      <td>0.960076</td>\n",
              "      <td>0.363902</td>\n",
              "      <td>0.962581</td>\n",
              "      <td>0.935908</td>\n",
              "      <td>0.094588</td>\n",
              "      <td>0.419872</td>\n",
              "      <td>0.504426</td>\n",
              "      <td>0.735387</td>\n",
              "      <td>0.154109</td>\n",
              "      <td>0.031018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Area</th>\n",
              "      <td>0.667035</td>\n",
              "      <td>0.987866</td>\n",
              "      <td>0.400284</td>\n",
              "      <td>0.986137</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100207</td>\n",
              "      <td>0.466542</td>\n",
              "      <td>0.632035</td>\n",
              "      <td>0.790454</td>\n",
              "      <td>0.127187</td>\n",
              "      <td>-0.296071</td>\n",
              "      <td>0.718999</td>\n",
              "      <td>-0.016383</td>\n",
              "      <td>0.714238</td>\n",
              "      <td>0.800204</td>\n",
              "      <td>-0.113326</td>\n",
              "      <td>0.214851</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.320326</td>\n",
              "      <td>-0.030732</td>\n",
              "      <td>-0.021158</td>\n",
              "      <td>0.946216</td>\n",
              "      <td>0.335767</td>\n",
              "      <td>0.942642</td>\n",
              "      <td>0.943687</td>\n",
              "      <td>0.060027</td>\n",
              "      <td>0.343284</td>\n",
              "      <td>0.447492</td>\n",
              "      <td>0.674052</td>\n",
              "      <td>0.094772</td>\n",
              "      <td>-0.023343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Smoothness</th>\n",
              "      <td>0.314811</td>\n",
              "      <td>0.093480</td>\n",
              "      <td>-0.009081</td>\n",
              "      <td>0.136422</td>\n",
              "      <td>0.100207</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.641173</td>\n",
              "      <td>0.530556</td>\n",
              "      <td>0.548984</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.602346</td>\n",
              "      <td>0.284035</td>\n",
              "      <td>0.093769</td>\n",
              "      <td>0.276355</td>\n",
              "      <td>0.231075</td>\n",
              "      <td>0.344493</td>\n",
              "      <td>0.366973</td>\n",
              "      <td>0.234304</td>\n",
              "      <td>0.329912</td>\n",
              "      <td>0.247269</td>\n",
              "      <td>0.308592</td>\n",
              "      <td>0.141084</td>\n",
              "      <td>0.039981</td>\n",
              "      <td>0.172760</td>\n",
              "      <td>0.133187</td>\n",
              "      <td>0.767162</td>\n",
              "      <td>0.476596</td>\n",
              "      <td>0.427929</td>\n",
              "      <td>0.473086</td>\n",
              "      <td>0.403487</td>\n",
              "      <td>0.503533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Compactness</th>\n",
              "      <td>0.574862</td>\n",
              "      <td>0.480938</td>\n",
              "      <td>0.290253</td>\n",
              "      <td>0.537753</td>\n",
              "      <td>0.466542</td>\n",
              "      <td>0.641173</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.882018</td>\n",
              "      <td>0.837872</td>\n",
              "      <td>0.622507</td>\n",
              "      <td>0.579548</td>\n",
              "      <td>0.499131</td>\n",
              "      <td>0.108756</td>\n",
              "      <td>0.547029</td>\n",
              "      <td>0.461093</td>\n",
              "      <td>0.134379</td>\n",
              "      <td>0.751579</td>\n",
              "      <td>0.502106</td>\n",
              "      <td>0.595981</td>\n",
              "      <td>0.295615</td>\n",
              "      <td>0.496100</td>\n",
              "      <td>0.515626</td>\n",
              "      <td>0.293007</td>\n",
              "      <td>0.574312</td>\n",
              "      <td>0.485344</td>\n",
              "      <td>0.531429</td>\n",
              "      <td>0.859178</td>\n",
              "      <td>0.796732</td>\n",
              "      <td>0.806720</td>\n",
              "      <td>0.536742</td>\n",
              "      <td>0.671440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Concavity</th>\n",
              "      <td>0.622877</td>\n",
              "      <td>0.626426</td>\n",
              "      <td>0.319960</td>\n",
              "      <td>0.670760</td>\n",
              "      <td>0.632035</td>\n",
              "      <td>0.530556</td>\n",
              "      <td>0.882018</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.906113</td>\n",
              "      <td>0.525676</td>\n",
              "      <td>0.400586</td>\n",
              "      <td>0.623912</td>\n",
              "      <td>0.141810</td>\n",
              "      <td>0.637533</td>\n",
              "      <td>0.607942</td>\n",
              "      <td>0.152112</td>\n",
              "      <td>0.697272</td>\n",
              "      <td>0.675275</td>\n",
              "      <td>0.662712</td>\n",
              "      <td>0.253480</td>\n",
              "      <td>0.493711</td>\n",
              "      <td>0.634134</td>\n",
              "      <td>0.301477</td>\n",
              "      <td>0.677017</td>\n",
              "      <td>0.618428</td>\n",
              "      <td>0.434185</td>\n",
              "      <td>0.723672</td>\n",
              "      <td>0.863081</td>\n",
              "      <td>0.828948</td>\n",
              "      <td>0.416502</td>\n",
              "      <td>0.513884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Concave_Points</th>\n",
              "      <td>0.732545</td>\n",
              "      <td>0.796443</td>\n",
              "      <td>0.341718</td>\n",
              "      <td>0.829846</td>\n",
              "      <td>0.790454</td>\n",
              "      <td>0.548984</td>\n",
              "      <td>0.837872</td>\n",
              "      <td>0.906113</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.488583</td>\n",
              "      <td>0.197440</td>\n",
              "      <td>0.692004</td>\n",
              "      <td>0.060270</td>\n",
              "      <td>0.701631</td>\n",
              "      <td>0.694567</td>\n",
              "      <td>0.063849</td>\n",
              "      <td>0.508674</td>\n",
              "      <td>0.378952</td>\n",
              "      <td>0.571547</td>\n",
              "      <td>0.147161</td>\n",
              "      <td>0.264812</td>\n",
              "      <td>0.801603</td>\n",
              "      <td>0.315289</td>\n",
              "      <td>0.831994</td>\n",
              "      <td>0.777381</td>\n",
              "      <td>0.431098</td>\n",
              "      <td>0.653413</td>\n",
              "      <td>0.717161</td>\n",
              "      <td>0.894042</td>\n",
              "      <td>0.373838</td>\n",
              "      <td>0.363538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Symmetry</th>\n",
              "      <td>0.299413</td>\n",
              "      <td>0.137387</td>\n",
              "      <td>0.057195</td>\n",
              "      <td>0.177127</td>\n",
              "      <td>0.127187</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.622507</td>\n",
              "      <td>0.525676</td>\n",
              "      <td>0.488583</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.497342</td>\n",
              "      <td>0.302865</td>\n",
              "      <td>0.150201</td>\n",
              "      <td>0.307747</td>\n",
              "      <td>0.222083</td>\n",
              "      <td>0.090671</td>\n",
              "      <td>0.433621</td>\n",
              "      <td>0.324775</td>\n",
              "      <td>0.370057</td>\n",
              "      <td>0.491645</td>\n",
              "      <td>0.342675</td>\n",
              "      <td>0.176432</td>\n",
              "      <td>0.088787</td>\n",
              "      <td>0.215244</td>\n",
              "      <td>0.155144</td>\n",
              "      <td>0.396922</td>\n",
              "      <td>0.488051</td>\n",
              "      <td>0.450147</td>\n",
              "      <td>0.454006</td>\n",
              "      <td>0.705513</td>\n",
              "      <td>0.440456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean_Fractal_Dimension</th>\n",
              "      <td>-0.010482</td>\n",
              "      <td>-0.321167</td>\n",
              "      <td>-0.074200</td>\n",
              "      <td>-0.265202</td>\n",
              "      <td>-0.296071</td>\n",
              "      <td>0.602346</td>\n",
              "      <td>0.579548</td>\n",
              "      <td>0.400586</td>\n",
              "      <td>0.197440</td>\n",
              "      <td>0.497342</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005697</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.041392</td>\n",
              "      <td>-0.085423</td>\n",
              "      <td>0.332319</td>\n",
              "      <td>0.585325</td>\n",
              "      <td>0.462722</td>\n",
              "      <td>0.343735</td>\n",
              "      <td>0.371762</td>\n",
              "      <td>0.700536</td>\n",
              "      <td>-0.255458</td>\n",
              "      <td>-0.029395</td>\n",
              "      <td>-0.204999</td>\n",
              "      <td>-0.240094</td>\n",
              "      <td>0.502224</td>\n",
              "      <td>0.496093</td>\n",
              "      <td>0.409352</td>\n",
              "      <td>0.203978</td>\n",
              "      <td>0.390225</td>\n",
              "      <td>0.763872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Radius_SE</th>\n",
              "      <td>0.503082</td>\n",
              "      <td>0.677440</td>\n",
              "      <td>0.253619</td>\n",
              "      <td>0.691965</td>\n",
              "      <td>0.718999</td>\n",
              "      <td>0.284035</td>\n",
              "      <td>0.499131</td>\n",
              "      <td>0.623912</td>\n",
              "      <td>0.692004</td>\n",
              "      <td>0.302865</td>\n",
              "      <td>0.005697</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.243406</td>\n",
              "      <td>0.972352</td>\n",
              "      <td>0.957211</td>\n",
              "      <td>0.201987</td>\n",
              "      <td>0.367348</td>\n",
              "      <td>0.322876</td>\n",
              "      <td>0.509779</td>\n",
              "      <td>0.301331</td>\n",
              "      <td>0.229880</td>\n",
              "      <td>0.674935</td>\n",
              "      <td>0.142677</td>\n",
              "      <td>0.684464</td>\n",
              "      <td>0.694026</td>\n",
              "      <td>0.082291</td>\n",
              "      <td>0.252988</td>\n",
              "      <td>0.346585</td>\n",
              "      <td>0.488826</td>\n",
              "      <td>0.060922</td>\n",
              "      <td>0.016892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Texture_SE</th>\n",
              "      <td>-0.044788</td>\n",
              "      <td>-0.046538</td>\n",
              "      <td>0.270159</td>\n",
              "      <td>-0.031106</td>\n",
              "      <td>-0.016383</td>\n",
              "      <td>0.093769</td>\n",
              "      <td>0.108756</td>\n",
              "      <td>0.141810</td>\n",
              "      <td>0.060270</td>\n",
              "      <td>0.150201</td>\n",
              "      <td>0.218418</td>\n",
              "      <td>0.243406</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.271154</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.303251</td>\n",
              "      <td>0.294706</td>\n",
              "      <td>0.258153</td>\n",
              "      <td>0.286454</td>\n",
              "      <td>0.415421</td>\n",
              "      <td>0.336815</td>\n",
              "      <td>-0.087932</td>\n",
              "      <td>0.280642</td>\n",
              "      <td>-0.068049</td>\n",
              "      <td>-0.060673</td>\n",
              "      <td>-0.115005</td>\n",
              "      <td>-0.061490</td>\n",
              "      <td>-0.035530</td>\n",
              "      <td>-0.109725</td>\n",
              "      <td>-0.118351</td>\n",
              "      <td>-0.009581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perimeter_SE</th>\n",
              "      <td>0.495760</td>\n",
              "      <td>0.673772</td>\n",
              "      <td>0.259921</td>\n",
              "      <td>0.695369</td>\n",
              "      <td>0.714238</td>\n",
              "      <td>0.276355</td>\n",
              "      <td>0.547029</td>\n",
              "      <td>0.637533</td>\n",
              "      <td>0.701631</td>\n",
              "      <td>0.307747</td>\n",
              "      <td>0.041392</td>\n",
              "      <td>0.972352</td>\n",
              "      <td>0.271154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.943062</td>\n",
              "      <td>0.189566</td>\n",
              "      <td>0.421028</td>\n",
              "      <td>0.324444</td>\n",
              "      <td>0.540103</td>\n",
              "      <td>0.344142</td>\n",
              "      <td>0.239608</td>\n",
              "      <td>0.655208</td>\n",
              "      <td>0.150441</td>\n",
              "      <td>0.684400</td>\n",
              "      <td>0.670118</td>\n",
              "      <td>0.069558</td>\n",
              "      <td>0.294990</td>\n",
              "      <td>0.363431</td>\n",
              "      <td>0.502277</td>\n",
              "      <td>0.075075</td>\n",
              "      <td>0.037362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Area_SE</th>\n",
              "      <td>0.503786</td>\n",
              "      <td>0.747920</td>\n",
              "      <td>0.259671</td>\n",
              "      <td>0.758219</td>\n",
              "      <td>0.800204</td>\n",
              "      <td>0.231075</td>\n",
              "      <td>0.461093</td>\n",
              "      <td>0.607942</td>\n",
              "      <td>0.694567</td>\n",
              "      <td>0.222083</td>\n",
              "      <td>-0.085423</td>\n",
              "      <td>0.957211</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.943062</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.132024</td>\n",
              "      <td>0.293268</td>\n",
              "      <td>0.247199</td>\n",
              "      <td>0.386144</td>\n",
              "      <td>0.215891</td>\n",
              "      <td>0.129655</td>\n",
              "      <td>0.727869</td>\n",
              "      <td>0.169519</td>\n",
              "      <td>0.734700</td>\n",
              "      <td>0.759050</td>\n",
              "      <td>0.071423</td>\n",
              "      <td>0.248083</td>\n",
              "      <td>0.344173</td>\n",
              "      <td>0.497246</td>\n",
              "      <td>0.039873</td>\n",
              "      <td>-0.013396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Smoothness_SE</th>\n",
              "      <td>-0.097301</td>\n",
              "      <td>-0.167242</td>\n",
              "      <td>-0.090914</td>\n",
              "      <td>-0.145823</td>\n",
              "      <td>-0.113326</td>\n",
              "      <td>0.344493</td>\n",
              "      <td>0.134379</td>\n",
              "      <td>0.152112</td>\n",
              "      <td>0.063849</td>\n",
              "      <td>0.090671</td>\n",
              "      <td>0.332319</td>\n",
              "      <td>0.201987</td>\n",
              "      <td>0.303251</td>\n",
              "      <td>0.189566</td>\n",
              "      <td>0.132024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.374699</td>\n",
              "      <td>0.316298</td>\n",
              "      <td>0.393147</td>\n",
              "      <td>0.346827</td>\n",
              "      <td>0.431826</td>\n",
              "      <td>-0.210786</td>\n",
              "      <td>-0.179556</td>\n",
              "      <td>-0.191481</td>\n",
              "      <td>-0.172195</td>\n",
              "      <td>0.251313</td>\n",
              "      <td>-0.068557</td>\n",
              "      <td>-0.044344</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>-0.162861</td>\n",
              "      <td>0.036588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Compactness_SE</th>\n",
              "      <td>0.279346</td>\n",
              "      <td>0.210850</td>\n",
              "      <td>0.193028</td>\n",
              "      <td>0.259057</td>\n",
              "      <td>0.214851</td>\n",
              "      <td>0.366973</td>\n",
              "      <td>0.751579</td>\n",
              "      <td>0.697272</td>\n",
              "      <td>0.508674</td>\n",
              "      <td>0.433621</td>\n",
              "      <td>0.585325</td>\n",
              "      <td>0.367348</td>\n",
              "      <td>0.294706</td>\n",
              "      <td>0.421028</td>\n",
              "      <td>0.293268</td>\n",
              "      <td>0.374699</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.759689</td>\n",
              "      <td>0.718673</td>\n",
              "      <td>0.458615</td>\n",
              "      <td>0.793503</td>\n",
              "      <td>0.199657</td>\n",
              "      <td>0.140524</td>\n",
              "      <td>0.257662</td>\n",
              "      <td>0.188619</td>\n",
              "      <td>0.226022</td>\n",
              "      <td>0.672486</td>\n",
              "      <td>0.645125</td>\n",
              "      <td>0.470539</td>\n",
              "      <td>0.312978</td>\n",
              "      <td>0.570630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Concavity_SE</th>\n",
              "      <td>0.163661</td>\n",
              "      <td>0.134393</td>\n",
              "      <td>0.101520</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.152767</td>\n",
              "      <td>0.234304</td>\n",
              "      <td>0.502106</td>\n",
              "      <td>0.675275</td>\n",
              "      <td>0.378952</td>\n",
              "      <td>0.324775</td>\n",
              "      <td>0.462722</td>\n",
              "      <td>0.322876</td>\n",
              "      <td>0.258153</td>\n",
              "      <td>0.324444</td>\n",
              "      <td>0.247199</td>\n",
              "      <td>0.316298</td>\n",
              "      <td>0.759689</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.760494</td>\n",
              "      <td>0.371987</td>\n",
              "      <td>0.752839</td>\n",
              "      <td>0.121498</td>\n",
              "      <td>0.055345</td>\n",
              "      <td>0.156335</td>\n",
              "      <td>0.125411</td>\n",
              "      <td>0.124195</td>\n",
              "      <td>0.398402</td>\n",
              "      <td>0.628329</td>\n",
              "      <td>0.363587</td>\n",
              "      <td>0.195292</td>\n",
              "      <td>0.384590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Concave_Points_SE</th>\n",
              "      <td>0.343616</td>\n",
              "      <td>0.328699</td>\n",
              "      <td>0.145774</td>\n",
              "      <td>0.361056</td>\n",
              "      <td>0.320326</td>\n",
              "      <td>0.329912</td>\n",
              "      <td>0.595981</td>\n",
              "      <td>0.662712</td>\n",
              "      <td>0.571547</td>\n",
              "      <td>0.370057</td>\n",
              "      <td>0.343735</td>\n",
              "      <td>0.509779</td>\n",
              "      <td>0.286454</td>\n",
              "      <td>0.540103</td>\n",
              "      <td>0.386144</td>\n",
              "      <td>0.393147</td>\n",
              "      <td>0.718673</td>\n",
              "      <td>0.760494</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388558</td>\n",
              "      <td>0.630059</td>\n",
              "      <td>0.298991</td>\n",
              "      <td>0.042076</td>\n",
              "      <td>0.337527</td>\n",
              "      <td>0.276401</td>\n",
              "      <td>0.136128</td>\n",
              "      <td>0.381483</td>\n",
              "      <td>0.501947</td>\n",
              "      <td>0.534901</td>\n",
              "      <td>0.133427</td>\n",
              "      <td>0.251643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Symmetry_SE</th>\n",
              "      <td>-0.034470</td>\n",
              "      <td>-0.063816</td>\n",
              "      <td>-0.074104</td>\n",
              "      <td>-0.035995</td>\n",
              "      <td>-0.030732</td>\n",
              "      <td>0.247269</td>\n",
              "      <td>0.295615</td>\n",
              "      <td>0.253480</td>\n",
              "      <td>0.147161</td>\n",
              "      <td>0.491645</td>\n",
              "      <td>0.371762</td>\n",
              "      <td>0.301331</td>\n",
              "      <td>0.415421</td>\n",
              "      <td>0.344142</td>\n",
              "      <td>0.215891</td>\n",
              "      <td>0.346827</td>\n",
              "      <td>0.458615</td>\n",
              "      <td>0.371987</td>\n",
              "      <td>0.388558</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.379462</td>\n",
              "      <td>-0.111882</td>\n",
              "      <td>-0.146486</td>\n",
              "      <td>-0.076681</td>\n",
              "      <td>-0.101813</td>\n",
              "      <td>-0.024373</td>\n",
              "      <td>0.109147</td>\n",
              "      <td>0.097621</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.416234</td>\n",
              "      <td>0.093815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fractal_Dimension_SE</th>\n",
              "      <td>0.047932</td>\n",
              "      <td>-0.045723</td>\n",
              "      <td>0.029167</td>\n",
              "      <td>-0.007175</td>\n",
              "      <td>-0.021158</td>\n",
              "      <td>0.308592</td>\n",
              "      <td>0.496100</td>\n",
              "      <td>0.493711</td>\n",
              "      <td>0.264812</td>\n",
              "      <td>0.342675</td>\n",
              "      <td>0.700536</td>\n",
              "      <td>0.229880</td>\n",
              "      <td>0.336815</td>\n",
              "      <td>0.239608</td>\n",
              "      <td>0.129655</td>\n",
              "      <td>0.431826</td>\n",
              "      <td>0.793503</td>\n",
              "      <td>0.752839</td>\n",
              "      <td>0.630059</td>\n",
              "      <td>0.379462</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.049852</td>\n",
              "      <td>-0.018292</td>\n",
              "      <td>-0.014577</td>\n",
              "      <td>-0.037337</td>\n",
              "      <td>0.154118</td>\n",
              "      <td>0.374498</td>\n",
              "      <td>0.402998</td>\n",
              "      <td>0.203271</td>\n",
              "      <td>0.129552</td>\n",
              "      <td>0.554114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Radius</th>\n",
              "      <td>0.757582</td>\n",
              "      <td>0.960578</td>\n",
              "      <td>0.452690</td>\n",
              "      <td>0.960076</td>\n",
              "      <td>0.946216</td>\n",
              "      <td>0.141084</td>\n",
              "      <td>0.515626</td>\n",
              "      <td>0.634134</td>\n",
              "      <td>0.801603</td>\n",
              "      <td>0.176432</td>\n",
              "      <td>-0.255458</td>\n",
              "      <td>0.674935</td>\n",
              "      <td>-0.087932</td>\n",
              "      <td>0.655208</td>\n",
              "      <td>0.727869</td>\n",
              "      <td>-0.210786</td>\n",
              "      <td>0.199657</td>\n",
              "      <td>0.121498</td>\n",
              "      <td>0.298991</td>\n",
              "      <td>-0.111882</td>\n",
              "      <td>-0.049852</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.440267</td>\n",
              "      <td>0.992816</td>\n",
              "      <td>0.985792</td>\n",
              "      <td>0.185176</td>\n",
              "      <td>0.455813</td>\n",
              "      <td>0.532632</td>\n",
              "      <td>0.766859</td>\n",
              "      <td>0.225640</td>\n",
              "      <td>0.092159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Texture</th>\n",
              "      <td>0.510923</td>\n",
              "      <td>0.358192</td>\n",
              "      <td>0.909996</td>\n",
              "      <td>0.363902</td>\n",
              "      <td>0.335767</td>\n",
              "      <td>0.039981</td>\n",
              "      <td>0.293007</td>\n",
              "      <td>0.301477</td>\n",
              "      <td>0.315289</td>\n",
              "      <td>0.088787</td>\n",
              "      <td>-0.029395</td>\n",
              "      <td>0.142677</td>\n",
              "      <td>0.280642</td>\n",
              "      <td>0.150441</td>\n",
              "      <td>0.169519</td>\n",
              "      <td>-0.179556</td>\n",
              "      <td>0.140524</td>\n",
              "      <td>0.055345</td>\n",
              "      <td>0.042076</td>\n",
              "      <td>-0.146486</td>\n",
              "      <td>-0.018292</td>\n",
              "      <td>0.440267</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.441512</td>\n",
              "      <td>0.424130</td>\n",
              "      <td>0.276255</td>\n",
              "      <td>0.422060</td>\n",
              "      <td>0.399865</td>\n",
              "      <td>0.412982</td>\n",
              "      <td>0.276106</td>\n",
              "      <td>0.286848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Perimeter</th>\n",
              "      <td>0.765564</td>\n",
              "      <td>0.956904</td>\n",
              "      <td>0.453423</td>\n",
              "      <td>0.962581</td>\n",
              "      <td>0.942642</td>\n",
              "      <td>0.172760</td>\n",
              "      <td>0.574312</td>\n",
              "      <td>0.677017</td>\n",
              "      <td>0.831994</td>\n",
              "      <td>0.215244</td>\n",
              "      <td>-0.204999</td>\n",
              "      <td>0.684464</td>\n",
              "      <td>-0.068049</td>\n",
              "      <td>0.684400</td>\n",
              "      <td>0.734700</td>\n",
              "      <td>-0.191481</td>\n",
              "      <td>0.257662</td>\n",
              "      <td>0.156335</td>\n",
              "      <td>0.337527</td>\n",
              "      <td>-0.076681</td>\n",
              "      <td>-0.014577</td>\n",
              "      <td>0.992816</td>\n",
              "      <td>0.441512</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.977422</td>\n",
              "      <td>0.207156</td>\n",
              "      <td>0.506423</td>\n",
              "      <td>0.571999</td>\n",
              "      <td>0.795081</td>\n",
              "      <td>0.253364</td>\n",
              "      <td>0.129642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Area</th>\n",
              "      <td>0.705765</td>\n",
              "      <td>0.936635</td>\n",
              "      <td>0.437695</td>\n",
              "      <td>0.935908</td>\n",
              "      <td>0.943687</td>\n",
              "      <td>0.133187</td>\n",
              "      <td>0.485344</td>\n",
              "      <td>0.618428</td>\n",
              "      <td>0.777381</td>\n",
              "      <td>0.155144</td>\n",
              "      <td>-0.240094</td>\n",
              "      <td>0.694026</td>\n",
              "      <td>-0.060673</td>\n",
              "      <td>0.670118</td>\n",
              "      <td>0.759050</td>\n",
              "      <td>-0.172195</td>\n",
              "      <td>0.188619</td>\n",
              "      <td>0.125411</td>\n",
              "      <td>0.276401</td>\n",
              "      <td>-0.101813</td>\n",
              "      <td>-0.037337</td>\n",
              "      <td>0.985792</td>\n",
              "      <td>0.424130</td>\n",
              "      <td>0.977422</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.176310</td>\n",
              "      <td>0.414721</td>\n",
              "      <td>0.502514</td>\n",
              "      <td>0.722749</td>\n",
              "      <td>0.184752</td>\n",
              "      <td>0.074153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Smoothness</th>\n",
              "      <td>0.411572</td>\n",
              "      <td>0.060297</td>\n",
              "      <td>0.122798</td>\n",
              "      <td>0.094588</td>\n",
              "      <td>0.060027</td>\n",
              "      <td>0.767162</td>\n",
              "      <td>0.531429</td>\n",
              "      <td>0.434185</td>\n",
              "      <td>0.431098</td>\n",
              "      <td>0.396922</td>\n",
              "      <td>0.502224</td>\n",
              "      <td>0.082291</td>\n",
              "      <td>-0.115005</td>\n",
              "      <td>0.069558</td>\n",
              "      <td>0.071423</td>\n",
              "      <td>0.251313</td>\n",
              "      <td>0.226022</td>\n",
              "      <td>0.124195</td>\n",
              "      <td>0.136128</td>\n",
              "      <td>-0.024373</td>\n",
              "      <td>0.154118</td>\n",
              "      <td>0.185176</td>\n",
              "      <td>0.276255</td>\n",
              "      <td>0.207156</td>\n",
              "      <td>0.176310</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.581686</td>\n",
              "      <td>0.533318</td>\n",
              "      <td>0.547021</td>\n",
              "      <td>0.514637</td>\n",
              "      <td>0.639132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Compactness</th>\n",
              "      <td>0.586005</td>\n",
              "      <td>0.374555</td>\n",
              "      <td>0.343081</td>\n",
              "      <td>0.419872</td>\n",
              "      <td>0.343284</td>\n",
              "      <td>0.476596</td>\n",
              "      <td>0.859178</td>\n",
              "      <td>0.723672</td>\n",
              "      <td>0.653413</td>\n",
              "      <td>0.488051</td>\n",
              "      <td>0.496093</td>\n",
              "      <td>0.252988</td>\n",
              "      <td>-0.061490</td>\n",
              "      <td>0.294990</td>\n",
              "      <td>0.248083</td>\n",
              "      <td>-0.068557</td>\n",
              "      <td>0.672486</td>\n",
              "      <td>0.398402</td>\n",
              "      <td>0.381483</td>\n",
              "      <td>0.109147</td>\n",
              "      <td>0.374498</td>\n",
              "      <td>0.455813</td>\n",
              "      <td>0.422060</td>\n",
              "      <td>0.506423</td>\n",
              "      <td>0.414721</td>\n",
              "      <td>0.581686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.874010</td>\n",
              "      <td>0.791149</td>\n",
              "      <td>0.653209</td>\n",
              "      <td>0.828803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Concavity</th>\n",
              "      <td>0.614477</td>\n",
              "      <td>0.465421</td>\n",
              "      <td>0.334205</td>\n",
              "      <td>0.504426</td>\n",
              "      <td>0.447492</td>\n",
              "      <td>0.427929</td>\n",
              "      <td>0.796732</td>\n",
              "      <td>0.863081</td>\n",
              "      <td>0.717161</td>\n",
              "      <td>0.450147</td>\n",
              "      <td>0.409352</td>\n",
              "      <td>0.346585</td>\n",
              "      <td>-0.035530</td>\n",
              "      <td>0.363431</td>\n",
              "      <td>0.344173</td>\n",
              "      <td>-0.044344</td>\n",
              "      <td>0.645125</td>\n",
              "      <td>0.628329</td>\n",
              "      <td>0.501947</td>\n",
              "      <td>0.097621</td>\n",
              "      <td>0.402998</td>\n",
              "      <td>0.532632</td>\n",
              "      <td>0.399865</td>\n",
              "      <td>0.571999</td>\n",
              "      <td>0.502514</td>\n",
              "      <td>0.533318</td>\n",
              "      <td>0.874010</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.833510</td>\n",
              "      <td>0.572426</td>\n",
              "      <td>0.712982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Concave_Points</th>\n",
              "      <td>0.782921</td>\n",
              "      <td>0.705700</td>\n",
              "      <td>0.365272</td>\n",
              "      <td>0.735387</td>\n",
              "      <td>0.674052</td>\n",
              "      <td>0.473086</td>\n",
              "      <td>0.806720</td>\n",
              "      <td>0.828948</td>\n",
              "      <td>0.894042</td>\n",
              "      <td>0.454006</td>\n",
              "      <td>0.203978</td>\n",
              "      <td>0.488826</td>\n",
              "      <td>-0.109725</td>\n",
              "      <td>0.502277</td>\n",
              "      <td>0.497246</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.470539</td>\n",
              "      <td>0.363587</td>\n",
              "      <td>0.534901</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.203271</td>\n",
              "      <td>0.766859</td>\n",
              "      <td>0.412982</td>\n",
              "      <td>0.795081</td>\n",
              "      <td>0.722749</td>\n",
              "      <td>0.547021</td>\n",
              "      <td>0.791149</td>\n",
              "      <td>0.833510</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.531925</td>\n",
              "      <td>0.523025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Symmetry</th>\n",
              "      <td>0.418117</td>\n",
              "      <td>0.125492</td>\n",
              "      <td>0.134964</td>\n",
              "      <td>0.154109</td>\n",
              "      <td>0.094772</td>\n",
              "      <td>0.403487</td>\n",
              "      <td>0.536742</td>\n",
              "      <td>0.416502</td>\n",
              "      <td>0.373838</td>\n",
              "      <td>0.705513</td>\n",
              "      <td>0.390225</td>\n",
              "      <td>0.060922</td>\n",
              "      <td>-0.118351</td>\n",
              "      <td>0.075075</td>\n",
              "      <td>0.039873</td>\n",
              "      <td>-0.162861</td>\n",
              "      <td>0.312978</td>\n",
              "      <td>0.195292</td>\n",
              "      <td>0.133427</td>\n",
              "      <td>0.416234</td>\n",
              "      <td>0.129552</td>\n",
              "      <td>0.225640</td>\n",
              "      <td>0.276106</td>\n",
              "      <td>0.253364</td>\n",
              "      <td>0.184752</td>\n",
              "      <td>0.514637</td>\n",
              "      <td>0.653209</td>\n",
              "      <td>0.572426</td>\n",
              "      <td>0.531925</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.582851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worst_Fractal_Dimension</th>\n",
              "      <td>0.337542</td>\n",
              "      <td>-0.014133</td>\n",
              "      <td>0.169448</td>\n",
              "      <td>0.031018</td>\n",
              "      <td>-0.023343</td>\n",
              "      <td>0.503533</td>\n",
              "      <td>0.671440</td>\n",
              "      <td>0.513884</td>\n",
              "      <td>0.363538</td>\n",
              "      <td>0.440456</td>\n",
              "      <td>0.763872</td>\n",
              "      <td>0.016892</td>\n",
              "      <td>-0.009581</td>\n",
              "      <td>0.037362</td>\n",
              "      <td>-0.013396</td>\n",
              "      <td>0.036588</td>\n",
              "      <td>0.570630</td>\n",
              "      <td>0.384590</td>\n",
              "      <td>0.251643</td>\n",
              "      <td>0.093815</td>\n",
              "      <td>0.554114</td>\n",
              "      <td>0.092159</td>\n",
              "      <td>0.286848</td>\n",
              "      <td>0.129642</td>\n",
              "      <td>0.074153</td>\n",
              "      <td>0.639132</td>\n",
              "      <td>0.828803</td>\n",
              "      <td>0.712982</td>\n",
              "      <td>0.523025</td>\n",
              "      <td>0.582851</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Diagnosis  ...  Worst_Fractal_Dimension\n",
              "Diagnosis                 1.000000  ...                 0.337542\n",
              "Mean_Radius               0.703347  ...                -0.014133\n",
              "Mean_Texture              0.485373  ...                 0.169448\n",
              "Mean_Perimeter            0.715981  ...                 0.031018\n",
              "Mean_Area                 0.667035  ...                -0.023343\n",
              "Mean_Smoothness           0.314811  ...                 0.503533\n",
              "Mean_Compactness          0.574862  ...                 0.671440\n",
              "Mean_Concavity            0.622877  ...                 0.513884\n",
              "Mean_Concave_Points       0.732545  ...                 0.363538\n",
              "Mean_Symmetry             0.299413  ...                 0.440456\n",
              "Mean_Fractal_Dimension   -0.010482  ...                 0.763872\n",
              "Radius_SE                 0.503082  ...                 0.016892\n",
              "Texture_SE               -0.044788  ...                -0.009581\n",
              "Perimeter_SE              0.495760  ...                 0.037362\n",
              "Area_SE                   0.503786  ...                -0.013396\n",
              "Smoothness_SE            -0.097301  ...                 0.036588\n",
              "Compactness_SE            0.279346  ...                 0.570630\n",
              "Concavity_SE              0.163661  ...                 0.384590\n",
              "Concave_Points_SE         0.343616  ...                 0.251643\n",
              "Symmetry_SE              -0.034470  ...                 0.093815\n",
              "Fractal_Dimension_SE      0.047932  ...                 0.554114\n",
              "Worst_Radius              0.757582  ...                 0.092159\n",
              "Worst_Texture             0.510923  ...                 0.286848\n",
              "Worst_Perimeter           0.765564  ...                 0.129642\n",
              "Worst_Area                0.705765  ...                 0.074153\n",
              "Worst_Smoothness          0.411572  ...                 0.639132\n",
              "Worst_Compactness         0.586005  ...                 0.828803\n",
              "Worst_Concavity           0.614477  ...                 0.712982\n",
              "Worst_Concave_Points      0.782921  ...                 0.523025\n",
              "Worst_Symmetry            0.418117  ...                 0.582851\n",
              "Worst_Fractal_Dimension   0.337542  ...                 1.000000\n",
              "\n",
              "[31 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJzjhwOkmmzq"
      },
      "source": [
        "# Training the linear regression model\n",
        "\n",
        "Here we are using linear regression to train the model to predict the diagnosis of breast cancer based on featurese in the trainingset as we can see here the model is accurately predicting the diagnosis of trainingset values, it has an r squared value of 1 which tells us that the fit is ideal for the training set.  This model also has a mean squared error of ~4.5 which tells us that the model is fairly accurate when predicting values in the trainingset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kz8R71_g0zy",
        "outputId": "3f3b5b1f-d868-4ad4-a54a-aa42cd6e466d"
      },
      "source": [
        "# Here we train a model to perform linear regression data set to predict the diagnosis\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "# create the linear regression model by fitting training set to the test set\n",
        "regression_model = LinearRegression().fit(X_train, X_test.Diagnosis)\n",
        "# Score the model and retrive r^2 value\n",
        "rSquared = regression_model.score(X_train, X_test.Diagnosis)\n",
        "prediction = regression_model.predict(X_test)\n",
        "print('r^2 value: ', rSquared)\n",
        "print('mean_squared_error value: ', mean_squared_error(X_test.Diagnosis, prediction))\n",
        "print('Prediction: ', regression_model.predict(X_test.head()))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  0.27255525297649896\n",
            "mean_squared_error value:  0.5285400688932151\n",
            "Prediction:  [1.50260288 0.52369395 0.18290219 0.42917882 0.44866673]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P-fhUQKf-UX"
      },
      "source": [
        "Below we perform our predictions on the testset as you can see it also ideally fitted based on the r squared value and has a very low mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuEG397yfg2I",
        "outputId": "271be705-d968-4334-d235-3d19c90fa23c"
      },
      "source": [
        "# issue here when trianing the model with the t estset it seems to produce mean radius instead of diagnosis not sure why\n",
        "prediction = regression_model.predict(testSet)\n",
        "print('r^2 value: ', regression_model.score(testSet, y))\n",
        "print('mean_squared_error value: ', mean_squared_error(testSet.Diagnosis, prediction))\n",
        "print('Prediction: ', regression_model.predict(testSet.head()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  -1.057256263954355\n",
            "mean_squared_error value:  6.486655671927631e-31\n",
            "Prediction:  [-4.81342481e-16 -2.39109274e-16  2.33787778e-16  6.30379136e-16\n",
            " -2.82137638e-16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "FLPpNx2d1w6_",
        "outputId": "e89e11f4-11a5-472c-d87c-8c1556c582de"
      },
      "source": [
        "# We can also train the model to predict values in the test set with a high degree of accuracy as shown below\n",
        "# In this example I have chosen to predict the mean radius of the test set based on the values in the trainingset\n",
        "y = trainingSet.Mean_Radius\n",
        "\n",
        "regression_model = LinearRegression().fit(trainingSet, y)\n",
        "rSquared = regression_model.score(trainingSet, y)\n",
        "prediction = regression_model.predict(trainingSet)\n",
        "print('r^2 value: ', rSquared)\n",
        "print('mean_squared_error value: ', mean_squared_error(trainingSet.Mean_Radius, prediction))\n",
        "print('Prediction training set: ', regression_model.predict(trainingSet.head()))\n",
        "plt.scatter(trainingSet.Mean_Radius.values,testSet.Mean_Radius.values)\n",
        "plt.plot(trainingSet.Mean_Radius,prediction, color='Red')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  1.0\n",
            "mean_squared_error value:  5.935814435807184e-27\n",
            "Prediction training set:  [17.99 20.57 19.69 11.42 20.29]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe15ed7f0d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 274
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGr0Ctt4eZ-b"
      },
      "source": [
        "# Examples of low and high correlation in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Zsy1970XoOZO",
        "outputId": "3f86cd90-b0d6-4e6b-e80d-2fcdfd344efc"
      },
      "source": [
        "# Example of positive Linear correlation between radius and perimeter\n",
        "# since these correlate highly we can remove one of them from set\n",
        "\n",
        "plt.scatter(trainingSet['Mean_Perimeter'],trainingSet['Mean_Radius'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe15ed74210>"
            ]
          },
          "metadata": {},
          "execution_count": 275
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hhwzfmxSoTtU",
        "outputId": "66eafc62-d80a-4930-8871-0761daf9881f"
      },
      "source": [
        "# example of low negative correlation\n",
        "plt.scatter(trainingSet['Mean_Fractal_Dimension'],trainingSet['Mean_Radius'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe15ec48810>"
            ]
          },
          "metadata": {},
          "execution_count": 276
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEhh-MN3TxmC"
      },
      "source": [
        "# KNN Predictions\n",
        "\n",
        "Here we are using KNN to make predictions based on a number of features fed into the model.  As we can see it's score is 0.84 which isn't perfect but it's better to avoid overfitting the model so that it can adapt to new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndm4DL8G1lG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5806a11-c0dc-4b5f-e975-bbd6e80860cc"
      },
      "source": [
        "# K Nearest Neighbour\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(trainingSet,testSet[['Diagnosis']])\n",
        "print(knn.score(trainingSet,testSet['Diagnosis']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.823943661971831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRpTbB2ysXs-",
        "outputId": "03a64e48-6a22-453c-de4f-d9441ddd1fea"
      },
      "source": [
        "testSet.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuntf9ZpWj4M",
        "outputId": "b801d127-cef4-42d4-ad05-793101554e2e"
      },
      "source": [
        "# Make prediction on testSet\n",
        "knn.predict(testSet)\n",
        "\n",
        "# maybe define list of features and use for loop to iterated\n",
        "\n",
        "# Taken from line 336 in dataset should be labelled as benign\n",
        "print(knn.predict([[-1,12.3,19.02,77.88,464.4,0.08313,0.04202,0.007756,0.008535,0.1539,0.05945,0.184,1.532,1.199,13.24,0.007881,0.008432,0.007004,0.006522,0.01939,0.002222,13.35,28.46,84.53,544.3,0.1222,0.09052,0.03619,0.03983,0.2554,0.07207]]))\n",
        "# Taken from line 402 of dataset should be malignant\n",
        "print(knn.predict([[-1,17.91,21.02,124.4,994,0.123,0.2576,0.3189,0.1198,0.2113,0.07115,0.403,0.7747,3.123,41.51,0.007159,0.03718,0.06165,0.01051,0.01591,0.005099,20.8,27.78,149.6,1304,0.1873,0.5917,0.9034,0.1964,0.3245,0.1198]]))\n",
        "# Taken from line 491 of dataset should be malignant\n",
        "print(knn.predict([[-1,16.69,20.2,107.1,857.6,0.07497,0.07112,0.03649,0.02307,0.1846,0.05325,0.2473,0.5679,1.775,22.95,0.002667,0.01446,0.01423,0.005297,0.01961,0.0017,19.18,26.56,127.3,1084,0.1009,0.292,0.2477,0.08737,0.4677,0.07623]]))\n",
        " # Taken from line 511 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1183,32.52,0.009538]]))\n",
        "# Taken from line 518 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1068,67.36,0.006176]]))\n",
        "# Line 470 should be malignant\n",
        "print(naive_bayes.predict([[0.09289,104.9,0.006766]]))\n",
        "# 324 Should be beningn\n",
        "print(naive_bayes.predict([[0.1134,16.57,0.00591]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZglfe8VT1ZP"
      },
      "source": [
        "# Naive Bayes prediction of diagnosis\n",
        "\n",
        "Here we use naive bayes on both sets to perform  the diagnosis based on a few features from the dataset, I choose the features used to train this model by randomly selecting features with low correlations, in Naive Bayes the weights of the features have no bearing on the output.  It was very interesting to see that the model is predicting accurately given the small number of trainingset features included in the model\n",
        "\n",
        "## References\n",
        "\n",
        "Sklearn documentation: https://scikit-learn.org/stable/modules/naive_bayes.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt8iXCKZNIvw",
        "outputId": "4e9affba-5717-4e99-851f-209639087f67"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(trainingSet[['Mean_Smoothness','Area_SE','Smoothness_SE']],trainingSet[['Diagnosis']])\n",
        "diagnosisPrediction = naive_bayes.predict(trainingSet[['Diagnosis']])\n",
        "print(diagnosisPrediction)\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        " % (trainingSet.shape[0], (trainingSet['Diagnosis'] != diagnosisPrediction).sum()))\n",
        "print('Score of the model: ',naive_bayes.score(trainingSet[['Mean_Smoothness','Area_SE','Smoothness_SE']],trainingSet[['Diagnosis']]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
            " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1]\n",
            "Number of mislabeled points out of a total 284 points : 0\n",
            "Score of the model:  0.8133802816901409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LlAxnEfQ8fC",
        "outputId": "a93f5171-f27d-42b2-8e4a-fd5081519b67"
      },
      "source": [
        "diagnosisPrediction = naive_bayes.predict(testSet[['Diagnosis']])\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        " % (testSet.shape[0], (testSet['Diagnosis'] != diagnosisPrediction).sum()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mislabeled points out of a total 284 points : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBeRLr5lZbKF"
      },
      "source": [
        "Let's make some predictions based on features from randomly selected rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCnd53LHXa9g",
        "outputId": "f59b4a16-f919-49b0-cc38-dff2102b9c11"
      },
      "source": [
        "# maybe define list of features and use for loop to iterated and randomize\n",
        "\n",
        "\n",
        "# Taken from line 336 in dataset should be labelled as benign\n",
        "print(naive_bayes.predict([[0.08313,13.24,0.007881]]))\n",
        " # Taken from line 511 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1183,32.52,0.009538]]))\n",
        "# Taken from line 518 in dataset should be labelled as Malignant\n",
        "print(naive_bayes.predict([[0.1068,67.36,0.006176]]))\n",
        "# Line 470 should be malignant\n",
        "print(naive_bayes.predict([[0.09289,104.9,0.006766]]))\n",
        "# 324 Should be beningn\n",
        "print(naive_bayes.predict([[0.1134,16.57,0.00591]]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTT46nyNZiLw"
      },
      "source": [
        "As we see above the model performs very well, not 100% perfect but good enough for classification as it predicted 4/5 or 80% of the diagnosis values for the given row\n",
        "Judiging by the Naive Bayes score we achieved which was around 81% this is to be expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIr--wdrUvT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc76803-2551-4be3-8f30-dd4971ef0ec6"
      },
      "source": [
        "\n",
        "# We drop these as seen above all of these correlate well with the mean_radius in both sets\n",
        "# removing these seems to reduce the mean squared error\n",
        "\n",
        "trainingSet = trainingSet.drop(['Mean_Perimeter'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Mean_Area'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Perimeter'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Area'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Mean_Concave_Points'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Texture'],axis=1)\n",
        "trainingSet = trainingSet.drop(['Worst_Fractal_Dimension'],axis=1)\n",
        "\n",
        "testSet = testSet.drop(['Mean_Perimeter'],axis=1)\n",
        "testSet = testSet.drop(['Mean_Area'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Perimeter'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Area'],axis=1)\n",
        "testSet = testSet.drop(['Mean_Concave_Points'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Texture'],axis=1)\n",
        "testSet = testSet.drop(['Worst_Fractal_Dimension'],axis=1)\n",
        "\n",
        "# Score the model and retrive r^2 value\n",
        "# Notice that both our rsquared and mean squared error values decrease after dropping these columns from dataframe\n",
        "print('r^2 value: ', rSquared)\n",
        "print('mean squared errors value: ', sqrt(mean_squared_error(trainingSet,testSet)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r^2 value:  1.0\n",
            "mean squared errors value:  13.339169290650567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWO-HmWlxlEf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}